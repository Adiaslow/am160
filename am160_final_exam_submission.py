# -*- coding: utf-8 -*-
"""am160_final_exam.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bPKy8Wtyp3Cdf_Hss2_Ad04vT0dJSYJy
"""

# @title Setup and Imports

# Install required dependencies
_ = !pip install netCDF4
_ = !pip install cartopy
_ = !pip install scikit-image

# Import core libraries
import os
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import cm
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torch.optim.lr_scheduler import _LRScheduler
from functools import partial
import netCDF4 as nc
from skimage.metrics import structural_similarity as ssim
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import cartopy.crs as ccrs
import matplotlib.patches as patches
from matplotlib.path import Path
import math
from tqdm.notebook import tqdm

# Set consistent random seeds for reproducibility
RANDOM_SEED = 137
np.random.seed(RANDOM_SEED)
torch.manual_seed(RANDOM_SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(RANDOM_SEED)

# Set default figure style
plt.style.use('seaborn-v0_8-whitegrid')
plt.rcParams.update({
    'figure.figsize': (12, 8),
    'axes.labelsize': 12,
    'axes.titlesize': 14,
    'xtick.labelsize': 10,
    'ytick.labelsize': 10,
    'legend.fontsize': 10,
})

# Device configuration
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

"""# CIRRUS: **C**ircular **I**nterpolation for **R**esidual **R**econstruction **U**sing **S**elf-attention

"""

# @title CIRRUS: Data Module

class WeatherDataProcessor:
    """
    Utility class for loading and preprocessing weather data from NetCDF files
    """
    @staticmethod
    def load_data_files(data_paths):
        """
        Load multiple NetCDF data files from given paths
        Args:
            data_paths (list): List of file paths to load
        Returns:
            dict: Dictionary containing loaded data indexed by file path
        """
        data = {}
        for file_path in data_paths:
            try:
                data[file_path] = nc.Dataset(file_path, 'r')
                print(f"Successfully loaded data from {file_path}")
            except Exception as e:
                print(f"Error loading data from {file_path}: {e}")
        return data

    @staticmethod
    def get_coordinates(data_obj):
        """
        Extract coordinate information from NetCDF object
        Args:
            data_obj: NetCDF dataset object
        Returns:
            tuple: (latitudes, longitudes)
        """
        if 'lat' in data_obj.variables:
            lats = data_obj.variables['lat'][:]
            lons = data_obj.variables['lon'][:]
        else:
            # Create dummy values if not available
            z_data = data_obj.variables['z'][:]
            lat_size = z_data.shape[2]
            lon_size = z_data.shape[3]
            lats = np.linspace(-90, 90, lat_size)
            lons = np.linspace(0, 360, lon_size)
        return lats, lons

    @staticmethod
    def get_data_info(data_obj):
        """
        Print information about data dimensions and available variables
        Args:
            data_obj: NetCDF dataset object
        """
        print("Data dimensions:")
        print("----------------")
        for dim_name, dim in data_obj.dimensions.items():
            print(f"{dim_name}: {len(dim)}")
        print("\nVariables:")
        print("----------")
        for var_name, var in data_obj.variables.items():
            print(f"{var_name}: {var.dimensions} {var.shape}")

    @staticmethod
    def visualize_sample(data_obj, time_steps, channels, lats, lons):
        """
        Create visualization of spatial patterns for selected time steps and channels
        Args:
            data_obj: NetCDF dataset object
            time_steps (list): List of time indices to visualize
            channels (list): List of channel indices to visualize
            lats (array): Latitude values
            lons (array): Longitude values
        Returns:
            matplotlib.figure.Figure: Figure object
        """
        z_data = data_obj.variables['z'][:]
        fig = plt.figure(figsize=(15, 10))
        for i, time_step in enumerate(time_steps):
            for j, channel in enumerate(channels):
                idx = i * len(channels) + j + 1
                # Create subplot with map projection
                ax = fig.add_subplot(len(time_steps), len(channels), idx,
                                    projection=ccrs.PlateCarree())
                # Create contour plot
                contour = ax.contourf(lons, lats, z_data[time_step, channel, :, :],
                                     transform=ccrs.PlateCarree(),
                                     cmap=cm.viridis, levels=20)
                # Add coastlines for reference
                ax.coastlines()
                # Add grid lines
                ax.gridlines(draw_labels=True, linewidth=0.5, color='gray', alpha=0.5)
                # Add title
                ax.set_title(f'Time: {time_step * 6}h (Channel: {channel})')
        # Add colorbar
        plt.colorbar(contour, ax=fig.axes, orientation='horizontal', pad=0.05, aspect=30, anchor=(0.5, -1))
        plt.subplots_adjust(wspace=0.5, hspace=0.5)
        return fig


class WeatherDataset(Dataset):
    """
    PyTorch Dataset for weather data with configurable sparsity and data augmentation
    """
    def __init__(self, file_paths, is_training=True, sparsity_ratio=0.3, normalize=True,
                 augmentation_config=None):
        """
        Initialize dataset
        Args:
            file_paths (list): List of paths to NetCDF files
            is_training (bool): Whether this is a training dataset
            sparsity_ratio (float): Ratio of data points to mask (0.0-1.0)
            normalize (bool): Whether to normalize the data
            augmentation_config (dict): Configuration for data augmentation:
                - circular_shift (bool): Whether to apply random circular shifts
                - vertical_flip (bool): Whether to apply random vertical flips
                - noise_injection (bool): Whether to apply random noise
                - shift_prob (float): Probability of applying circular shift
                - flip_prob (float): Probability of applying vertical flip
                - noise_prob (float): Probability of applying noise
                - noise_scale (float): Scale factor for noise (relative to data std)
                - max_shift_percent (float): Maximum shift as percentage of longitude (0.0-1.0)
        """
        self.data = []
        for file_path in file_paths:
            ds = nc.Dataset(file_path, 'r')
            # Extract z variable
            z = ds.variables['z'][:]
            self.data.append(z)
            ds.close()
        # Concatenate data from multiple files
        self.data = np.concatenate(self.data, axis=0)
        # Store original data statistics
        self.orig_mean = np.mean(self.data)
        self.orig_std = np.std(self.data)
        # Normalize data if requested
        if normalize:
            self.data = (self.data - self.orig_mean) / self.orig_std
        self.is_training = is_training
        self.sparsity_ratio = sparsity_ratio
        self.normalize = normalize

        # Default augmentation config
        default_config = {
            'circular_shift': False,
            'vertical_flip': False,
            'noise_injection': False,
            'shift_prob': 0.5,
            'flip_prob': 0.3,
            'noise_prob': 0.3,
            'noise_scale': 0.05,
            'max_shift_percent': 1.0
        }

        # Use provided config or default
        self.augmentation_config = augmentation_config if augmentation_config is not None else default_config

    def __len__(self):
        return len(self.data)

    def apply_augmentations(self, data, mask):
        """
        Apply configured augmentations to the data

        Args:
            data: Input array of shape [D, H, W]
            mask: Mask array of the same shape

        Returns:
            Augmented data and mask
        """
        # Only apply augmentations during training
        if not self.is_training:
            return data, mask

        config = self.augmentation_config

        # 1. Random circular shift in longitude
        if config.get('circular_shift', False) and np.random.random() < config.get('shift_prob', 0.5):
            lon_size = data.shape[-1]
            max_shift = int(lon_size * config.get('max_shift_percent', 1.0))
            shift = np.random.randint(1, max_shift + 1) if max_shift > 0 else 0

            if shift > 0:
                data = np.roll(data, shift=shift, axis=-1)
                mask = np.roll(mask, shift=shift, axis=-1)

        # 2. Random vertical flip (across equator)
        if config.get('vertical_flip', False) and np.random.random() < config.get('flip_prob', 0.3):
            data = np.flip(data, axis=-2).copy()  # Flip height dimension (latitude)
            mask = np.flip(mask, axis=-2).copy()

        # 3. Random noise injection
        if config.get('noise_injection', False) and np.random.random() < config.get('noise_prob', 0.3):
            # Generate noise with scale proportional to data std
            noise_amplitude = self.orig_std * config.get('noise_scale', 0.05) if not self.normalize else config.get('noise_scale', 0.05)
            noise = np.random.normal(0, noise_amplitude, data.shape)
            # Only add noise to unmasked areas
            data = data + noise * mask

        return data, mask

    def __getitem__(self, idx):
        # Get original sample
        X = self.data[idx].copy()  # Shape: [2, 91, 180]

        # Create mask for sparsity (1 for kept values, 0 for masked values)
        mask = np.ones_like(X)

        # Create sparsity by randomly selecting points to mask
        num_points = X.shape[0] * X.shape[1] * X.shape[2]
        num_to_mask = int(num_points * self.sparsity_ratio)

        # Flatten mask, randomly select indices, and set to 0
        flat_mask = mask.flatten()
        indices_to_mask = np.random.choice(num_points, num_to_mask, replace=False)
        flat_mask[indices_to_mask] = 0

        # Reshape mask back to original shape
        mask = flat_mask.reshape(X.shape)

        # Apply data augmentation ONLY during training
        if self.is_training:
            X, mask = self.apply_augmentations(X, mask)

        # Apply mask to create corrupted input
        X_corrupted = X * mask

        # [rest of the code]

        # Add channel dimension for Conv3D (expected shape: [C, D, H, W])
        # Where D is our 2 levels
        X = X.reshape(1, *X.shape)  # Shape: [1, 2, 91, 180]
        X_corrupted = X_corrupted.reshape(1, *X_corrupted.shape)  # Shape: [1, 2, 91, 180]
        mask = mask.reshape(1, *mask.shape)  # Shape: [1, 2, 91, 180]

        return {
            'original': torch.FloatTensor(X),
            'corrupted': torch.FloatTensor(X_corrupted),
            'mask': torch.FloatTensor(mask)
        }

    def denormalize(self, data):
        """
        Convert normalized data back to original scale
        Args:
            data: Normalized data tensor or array
        Returns:
            Denormalized data in original scale
        """
        if self.normalize:
            if isinstance(data, torch.Tensor):
                return data * self.orig_std + self.orig_mean
            else:
                return data * self.orig_std + self.orig_mean
        return data


def visualize_augmentations(dataset, sample_idx=0, n_augmentations=5):
    """
    Visualize different augmentations of the same sample

    Args:
        dataset: WeatherDataset instance
        sample_idx: Index of sample to visualize
        n_augmentations: Number of augmentations to generate

    Returns:
        matplotlib figure
    """
    # Get the original sample without augmentation
    orig_config = dataset.augmentation_config.copy()
    # Temporarily disable augmentation
    dataset.augmentation_config = {
        'circular_shift': False,
        'vertical_flip': False,
        'noise_injection': False
    }

    # Get original sample
    orig_sample = dataset[sample_idx]['original'][0]  # Remove channel dim

    # Restore augmentation config
    dataset.augmentation_config = orig_config

    # Force augmentation for visualization
    temp_training = dataset.is_training
    dataset.is_training = True

    # Generate augmented samples
    aug_samples = []
    for i in range(n_augmentations):
        aug_sample = dataset[sample_idx]['original'][0]  # Remove channel dim
        aug_samples.append(aug_sample)

    # Restore original setting
    dataset.is_training = temp_training

    # Plot
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    plt.subplots_adjust(hspace=0.3)

    # Plot original sample (first level)
    ax = axes[0, 0]
    im = ax.imshow(orig_sample[0], cmap='viridis')
    ax.set_title('Original (Level 1)')
    ax.set_xlabel('Longitude')
    ax.set_ylabel('Latitude')

    # Plot original sample (second level)
    ax = axes[1, 0]
    im = ax.imshow(orig_sample[1], cmap='viridis')
    ax.set_title('Original (Level 2)')
    ax.set_xlabel('Longitude')
    ax.set_ylabel('Latitude')

    # Plot augmentations (both levels, different augmentations)
    for i in range(2):
        for j in range(1, 3):
            aug_idx = i*2 + j - 1
            if aug_idx < len(aug_samples):
                ax = axes[i, j]
                level = 0 if i == 0 else 1
                im = ax.imshow(aug_samples[aug_idx][level], cmap='viridis')
                ax.set_title(f'Augmentation {aug_idx+1} (Level {level+1})')
                ax.set_xlabel('Longitude')
                ax.set_ylabel('Latitude')

    plt.colorbar(im, ax=axes, orientation='horizontal', pad=0.05)
    plt.tight_layout()

    return fig

# @title CIRRUS: Model Architecture

class CircularPad3d(nn.Module):
    def __init__(self, padding):
        super().__init__()
        self.padding = padding

    def forward(self, x):
        if self.padding <= 0:
            return x

        # First pad all dimensions except longitude with zeros
        x_padded = F.pad(
            x,
            (0, 0,  # Don't pad longitude yet
             self.padding, self.padding,  # Pad latitude (height)
             self.padding, self.padding),  # Pad depth
            mode='constant',
            value=0
        )

        # Now handle longitude with circular padding
        batch_size, channels, depth, height, width = x_padded.shape

        # Use indexing operations that precisely mimic the circular nature
        # Extract rightmost columns for left padding
        left_pad = x_padded[:, :, :, :, -self.padding:].clone()
        # Extract leftmost columns for right padding
        right_pad = x_padded[:, :, :, :, :self.padding].clone()

        # Concatenate with main tensor for perfect circular padding
        output = torch.cat([left_pad, x_padded, right_pad], dim=4)

        return output


class ConvBlock(nn.Module):
    """
    3D Convolutional block with batch normalization and ReLU activation
    Dropout has been removed in favor of weight regularization
    """
    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, use_circular_pad=True):
        super().__init__()
        self.use_circular_pad = use_circular_pad
        if use_circular_pad:
            self.pad = CircularPad3d(padding)
            self.conv = nn.Conv3d(in_channels, out_channels, kernel_size, stride, padding=0)
        else:
            self.conv = nn.Conv3d(in_channels, out_channels, kernel_size, stride, padding=padding)

        self.bn = nn.BatchNorm3d(out_channels)
        self.relu = nn.ReLU(inplace=True)

    def forward(self, x):
        """Forward pass"""
        if self.use_circular_pad:
            x = self.pad(x)

        x = self.conv(x)
        x = self.bn(x)
        x = self.relu(x)
        return x


class DeconvBlock(nn.Module):
    """
    3D Transposed convolutional block with batch normalization and ReLU activation
    Dropout has been removed in favor of weight regularization
    """
    def __init__(self, in_channels, out_channels, kernel_size=4, stride=2, padding=1, output_padding=0):
        super().__init__()
        self.deconv = nn.ConvTranspose3d(
            in_channels, out_channels,
            kernel_size, stride,
            padding, output_padding=output_padding
        )
        self.bn = nn.BatchNorm3d(out_channels)
        self.relu = nn.ReLU(inplace=True)

    def forward(self, x):
        """Forward pass"""
        x = self.deconv(x)
        x = self.bn(x)
        x = self.relu(x)
        return x


class ChannelAttention(nn.Module):
    """
    Channel attention module for 3D data
    Dropout has been removed in favor of weight regularization
    """
    def __init__(self, channels, reduction_ratio=16):
        super().__init__()
        self.avg_pool = nn.AdaptiveAvgPool3d(1)
        self.max_pool = nn.AdaptiveMaxPool3d(1)

        reduced_channels = max(channels // reduction_ratio, 8)

        self.fc = nn.Sequential(
            nn.Linear(channels, reduced_channels, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(reduced_channels, channels, bias=False),
        )
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        batch_size, channels = x.size()[:2]

        # Average pooling
        avg_pool = self.avg_pool(x).view(batch_size, channels)
        avg_out = self.fc(avg_pool)

        # Max pooling
        max_pool = self.max_pool(x).view(batch_size, channels)
        max_out = self.fc(max_pool)

        # Combine and apply sigmoid
        out = self.sigmoid(avg_out + max_out).view(batch_size, channels, 1, 1, 1)
        return x * out


class SpatialAttention(nn.Module):
    """
    Spatial attention module for 3D data with safe circular padding
    """
    def __init__(self, kernel_size=7):
        super().__init__()
        self.kernel_size = kernel_size
        padding = kernel_size // 2

        # Use standard padding in the convolution instead of circular padding
        # This is safer and prevents the "wrapping around more than once" error
        self.conv = nn.Conv3d(2, 1, kernel_size, padding=padding, bias=False)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        # Generate average and max pooled features across channels
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)

        # Concatenate and apply convolution with built-in padding
        y = torch.cat([avg_out, max_out], dim=1)

        # Use the built-in padding in conv3d instead of separate padding layer
        y = self.conv(y)
        y = self.sigmoid(y)

        return x * y


class AttentionBlock(nn.Module):
    """
    Combined channel and spatial attention block for 3D data
    Dropout has been removed in favor of weight regularization
    """
    def __init__(self, channels, reduction_ratio=16, kernel_size=7):
        super().__init__()
        self.channel_attention = ChannelAttention(channels, reduction_ratio)
        self.spatial_attention = SpatialAttention(kernel_size)

    def forward(self, x):
        x = self.channel_attention(x)
        x = self.spatial_attention(x)
        return x


class SelfAttention3D(nn.Module):
    """
    Self-attention module for 3D data
    Dropout has been removed in favor of weight regularization
    """
    def __init__(self, channels):
        super().__init__()
        self.query = nn.Conv3d(channels, channels // 8, kernel_size=1)
        self.key = nn.Conv3d(channels, channels // 8, kernel_size=1)
        self.value = nn.Conv3d(channels, channels, kernel_size=1)
        self.gamma = nn.Parameter(torch.zeros(1))

    def forward(self, x):
        batch_size, C, D, H, W = x.size()

        # Flatten spatial dimensions
        query = self.query(x).view(batch_size, -1, D * H * W).permute(0, 2, 1)  # B x (D*H*W) x C'
        key = self.key(x).view(batch_size, -1, D * H * W)  # B x C' x (D*H*W)
        value = self.value(x).view(batch_size, -1, D * H * W)  # B x C x (D*H*W)

        # Compute attention map
        attention = F.softmax(torch.bmm(query, key), dim=1)  # B x (D*H*W) x (D*H*W)

        # Apply attention to value
        out = torch.bmm(value, attention.permute(0, 2, 1))  # B x C x (D*H*W)
        out = out.view(batch_size, C, D, H, W)

        # Add residual connection with learnable weight
        out = self.gamma * out + x

        return out


class ResidualBlock(nn.Module):
    """
    3D residual block with two convolutions and a skip connection
    Dropout has been removed in favor of weight regularization
    """
    def __init__(self, in_channels, out_channels, stride=1, use_circular_pad=True):
        super().__init__()

        self.use_circular_pad = use_circular_pad

        # First convolution with circular padding
        if use_circular_pad:
            self.pad1 = CircularPad3d(1)
            self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=3,
                                stride=stride, padding=0, bias=False)
        else:
            self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=3,
                                stride=stride, padding=1, bias=False)

        self.bn1 = nn.BatchNorm3d(out_channels)

        # Second convolution with circular padding
        if use_circular_pad:
            self.pad2 = CircularPad3d(1)
            self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=3,
                                stride=1, padding=0, bias=False)
        else:
            self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=3,
                                stride=1, padding=1, bias=False)

        self.bn2 = nn.BatchNorm3d(out_channels)

        # Skip connection
        self.shortcut = nn.Sequential()
        if stride != 1 or in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv3d(in_channels, out_channels, kernel_size=1,
                         stride=stride, bias=False),
                nn.BatchNorm3d(out_channels)
            )

        # Activation function
        self.relu = nn.ReLU(inplace=True)

    def forward(self, x):
        residual = x

        # First conv block with circular padding if enabled
        if self.use_circular_pad:
            out = self.pad1(x)
            out = self.conv1(out)
        else:
            out = self.conv1(x)

        out = self.bn1(out)
        out = self.relu(out)

        # Second conv block with circular padding if enabled
        if self.use_circular_pad:
            out = self.pad2(out)
            out = self.conv2(out)
        else:
            out = self.conv2(out)

        out = self.bn2(out)

        out += self.shortcut(residual)
        out = self.relu(out)

        return out


class WeatherDVAE(nn.Module):
    """
    Enhanced Denoising Variational Autoencoder for weather data with residual connections,
    circular padding, and U-Net style skip connections.
    Dropout has been replaced with weight regularization (to be applied in the optimizer).
    """

    def __init__(self, latent_dim=128, use_attention=True, use_circular_pad=True):
        """
        Initialize the Enhanced Weather DVAE

        Args:
            latent_dim (int): Dimension of latent space
            use_attention (bool): Whether to use attention mechanisms
            use_circular_pad (bool): Whether to use circular padding
        """
        super().__init__()

        # Save configuration
        self.latent_dim = latent_dim
        self.use_attention = use_attention
        self.use_circular_pad = use_circular_pad

        # Encoder with residual blocks
        self.enc_conv1 = ConvBlock(2, 16, kernel_size=3, stride=1, padding=1,
                                   use_circular_pad=use_circular_pad)
        self.enc_res1 = ResidualBlock(16, 16, use_circular_pad=use_circular_pad)
        self.enc_pool1 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))

        self.enc_conv2 = ConvBlock(16, 32, kernel_size=3, stride=1, padding=1,
                                   use_circular_pad=use_circular_pad)
        self.enc_res2 = ResidualBlock(32, 32, use_circular_pad=use_circular_pad)
        self.enc_pool2 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))

        self.enc_conv3 = ConvBlock(32, 64, kernel_size=3, stride=1, padding=1,
                                   use_circular_pad=use_circular_pad)
        self.enc_res3 = ResidualBlock(64, 64, use_circular_pad=use_circular_pad)
        self.enc_pool3 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))

        self.enc_conv4 = ConvBlock(64, 128, kernel_size=3, stride=1, padding=1,
                                   use_circular_pad=use_circular_pad)
        self.enc_res4 = ResidualBlock(128, 128, use_circular_pad=use_circular_pad)
        self.enc_pool4 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))

        # Attention blocks for encoder
        if use_attention:
            self.enc_attn1 = AttentionBlock(16)
            self.enc_attn2 = AttentionBlock(32)
            self.enc_attn3 = AttentionBlock(64)
            self.enc_attn4 = AttentionBlock(128)
            self.enc_self_attn = SelfAttention3D(128)

        # Calculate flattened size
        self.flatten_size = 128 * 2 * 5 * 11  # = 14080

        # Variational components
        self.fc_mu = nn.Linear(self.flatten_size, latent_dim)
        self.fc_logvar = nn.Linear(self.flatten_size, latent_dim)
        self.fc_decoder = nn.Linear(latent_dim, self.flatten_size)

        # Decoder network
        self.dec_conv1 = DeconvBlock(128, 64, kernel_size=4, stride=(1, 2, 2), padding=1)

        # Additional convolutional layers to handle skip connections
        self.skip_conv1 = ConvBlock(64 + 128, 64, kernel_size=1, stride=1, padding=0,
                                    use_circular_pad=False)
        self.dec_res1 = ResidualBlock(64, 64, use_circular_pad=use_circular_pad)

        self.dec_conv2 = DeconvBlock(64, 32, kernel_size=4, stride=(1, 2, 2), padding=1)
        self.skip_conv2 = ConvBlock(32 + 64, 32, kernel_size=1, stride=1, padding=0,
                                    use_circular_pad=False)
        self.dec_res2 = ResidualBlock(32, 32, use_circular_pad=use_circular_pad)

        self.dec_conv3 = DeconvBlock(32, 16, kernel_size=4, stride=(1, 2, 2), padding=1)
        self.skip_conv3 = ConvBlock(16 + 32, 16, kernel_size=1, stride=1, padding=0,
                                    use_circular_pad=False)
        self.dec_res3 = ResidualBlock(16, 16, use_circular_pad=use_circular_pad)

        self.dec_conv4 = DeconvBlock(16, 8, kernel_size=4, stride=(1, 2, 2), padding=1,
                                     output_padding=(0, 1, 0))
        self.dec_res4 = ResidualBlock(8, 8, use_circular_pad=use_circular_pad)

        # Final convolution with circular padding for the output
        if use_circular_pad:
            self.final_pad = CircularPad3d(1)
            self.final_conv = nn.Conv3d(8, 1, kernel_size=3, padding=0)
        else:
            self.final_conv = nn.Conv3d(8, 1, kernel_size=3, padding=1)

        # Attention blocks for decoder
        if use_attention:
            self.dec_attn1 = AttentionBlock(64)
            self.dec_attn2 = AttentionBlock(32)
            self.dec_attn3 = AttentionBlock(16)
            self.dec_attn4 = AttentionBlock(8)
            self.dec_self_attn = SelfAttention3D(64)

    def encode(self, x, mask):
        """
        Encode input data into latent space parameters

        Args:
            x: Input data tensor
            mask: Mask tensor (1 for known values, 0 for missing)

        Returns:
            tuple: (mu, logvar) of latent space distribution
        """
        # Concatenate input and mask along channel dimension
        x_with_mask = torch.cat([x, mask], dim=1)  # [batch, 2, 2, 91, 180]

        # Apply encoder layers with residual connections and attention
        # Save activations for skip connections

        e1 = self.enc_conv1(x_with_mask)
        e1 = self.enc_res1(e1)
        if self.use_attention:
            e1 = self.enc_attn1(e1)
        e1_pool = self.enc_pool1(e1)

        e2 = self.enc_conv2(e1_pool)
        e2 = self.enc_res2(e2)
        if self.use_attention:
            e2 = self.enc_attn2(e2)
        e2_pool = self.enc_pool2(e2)

        e3 = self.enc_conv3(e2_pool)
        e3 = self.enc_res3(e3)
        if self.use_attention:
            e3 = self.enc_attn3(e3)
        e3_pool = self.enc_pool3(e3)

        e4 = self.enc_conv4(e3_pool)
        e4 = self.enc_res4(e4)
        if self.use_attention:
            e4 = self.enc_attn4(e4)
            e4 = self.enc_self_attn(e4)
        e4_pool = self.enc_pool4(e4)

        h_flat = e4_pool.flatten(1)  # Flatten all dimensions except batch

        # Store encoder activations for skip connections
        self.skip_connections = [e1, e2, e3, e4]

        return self.fc_mu(h_flat), self.fc_logvar(h_flat)

    def reparameterize(self, mu, logvar):
        """
        Perform reparameterization trick for VAE

        Args:
            mu: Mean of latent distribution
            logvar: Log variance of latent distribution

        Returns:
            Sampled latent vector
        """
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std

    def decode(self, z):
        """
        Decode latent vector to reconstruction

        Args:
            z: Latent vector

        Returns:
            Reconstructed data tensor
        """
        h = self.fc_decoder(z)  # [batch, flatten_size]

        # Reshape to match encoder output shape
        h = h.view(-1, 128, 2, 5, 11)

        # Apply decoder layers with residual connections, attention and skip connections

        # Decoder level 1
        h = self.dec_conv1(h)
        if self.use_attention:
            h = self.dec_self_attn(h)
            h = self.dec_attn1(h)

        # Add skip connection from encoder (e4)
        skip4 = F.interpolate(self.skip_connections[3], size=h.shape[2:], mode='trilinear', align_corners=False)
        h = torch.cat([h, skip4], dim=1)  # Concat channels
        h = self.skip_conv1(h)  # 1x1 conv to reduce channels
        h = self.dec_res1(h)  # Apply residual block

        # Decoder level 2
        h = self.dec_conv2(h)
        if self.use_attention:
            h = self.dec_attn2(h)

        # Add skip connection from encoder (e3)
        skip3 = F.interpolate(self.skip_connections[2], size=h.shape[2:], mode='trilinear', align_corners=False)
        h = torch.cat([h, skip3], dim=1)  # Concat channels
        h = self.skip_conv2(h)  # 1x1 conv to reduce channels
        h = self.dec_res2(h)  # Apply residual block

        # Decoder level 3
        h = self.dec_conv3(h)
        if self.use_attention:
            h = self.dec_attn3(h)

        # Add skip connection from encoder (e2)
        skip2 = F.interpolate(self.skip_connections[1], size=h.shape[2:], mode='trilinear', align_corners=False)
        h = torch.cat([h, skip2], dim=1)  # Concat channels
        h = self.skip_conv3(h)  # 1x1 conv to reduce channels
        h = self.dec_res3(h)  # Apply residual block

        # Decoder level 4
        h = self.dec_conv4(h)
        if self.use_attention:
            h = self.dec_attn4(h)
        h = self.dec_res4(h)

        # Final convolution to get output with circular padding if enabled
        if self.use_circular_pad:
            h = self.final_pad(h)
            h = self.final_conv(h)
        else:
            h = self.final_conv(h)

        # Ensure output has the correct size using interpolation if needed
        # Expected final shape is [batch, 1, 2, 91, 180]
        expected_shape = (2, 91, 180)
        if (h.shape[-3:] != expected_shape):
            h = F.interpolate(
                h,
                size=expected_shape,
                mode='trilinear',
                align_corners=False
            )

        h = torch.clamp(h, -5.0, 5.0)
        return h

    def forward(self, x, mask):
        # Standard forward pass with explicit handling of circularity
        mu, logvar = self.encode(x, mask)
        z = self.reparameterize(mu, logvar)
        recon = self.decode(z)

        # Ensure output shape matches input
        if recon.shape != x.shape:
            recon = F.interpolate(
                recon,
                size=x.shape[2:],
                mode='trilinear',
                align_corners=False
            )

        # Explicitly enforce circularity in the final output
        # by averaging the first and last columns
        batch_size, channels, depth, height, width = recon.shape

        # Create a mask for longitude boundary values
        boundary_mask = torch.zeros_like(recon)
        boundary_mask[:, :, :, :, 0] = 1.0  # First column
        boundary_mask[:, :, :, :, -1] = 1.0  # Last column

        # Calculate average of boundary values
        boundary_sum = (recon[:, :, :, :, 0] + recon[:, :, :, :, -1]).unsqueeze(-1)
        boundary_avg = boundary_sum / 2.0

        # Replace boundary values with average
        boundary_avg_expanded = torch.cat([boundary_avg, boundary_avg], dim=-1)
        boundary_expanded = torch.zeros_like(recon)
        boundary_expanded[:, :, :, :, 0] = boundary_avg.squeeze(-1)
        boundary_expanded[:, :, :, :, -1] = boundary_avg.squeeze(-1)

        # Apply boundary averaging
        recon = recon * (1 - boundary_mask) + boundary_expanded * boundary_mask

        return recon, mu, logvar

# @title CIRRUS: Training Module

def weather_dvae_loss(recon_x, x, mu, logvar, mask, loss_weights=None):
    """
    Enhanced loss function for the weather denoising VAE

    Args:
        recon_x: Reconstructed data [batch, 1, 2, 91, 180]
        x: Original data [batch, 1, 2, 91, 180]
        mu: Mean of latent distribution
        logvar: Log variance of latent distribution
        mask: Binary mask (1 for known values, 0 for masked values)
        loss_weights: Optional dictionary with weights for loss components

    Returns:
        tuple: (Total weighted loss, Loss components dictionary)
    """
    # Default loss component weights
    if loss_weights is None:
        loss_weights = {
            'reconstruction': 0.59,
            'kl': 0.01,
            'gradient': 0.2,
            'multiscale': 0.2
        }

    # Get batch size for normalization
    batch_size = x.size(0)

    # 1. Basic reconstruction loss on masked areas
    inv_mask = 1 - mask  # Inverse mask to focus on masked regions
    masked_mse = F.mse_loss(recon_x * inv_mask, x * inv_mask, reduction='sum')

    # 2. Spatial gradient preservation (weather patterns have important spatial gradients)
    # Calculate gradients in latitude and longitude directions
    grad_lat_true = x[:, :, :, 1:, :] - x[:, :, :, :-1, :]  # Latitude gradient
    grad_lon_true = x[:, :, :, :, 1:] - x[:, :, :, :, :-1]  # Longitude gradient

    grad_lat_pred = recon_x[:, :, :, 1:, :] - recon_x[:, :, :, :-1, :]
    grad_lon_pred = recon_x[:, :, :, :, 1:] - recon_x[:, :, :, :, :-1]

    grad_lat_loss = F.mse_loss(grad_lat_pred, grad_lat_true, reduction='sum')
    grad_lon_loss = F.mse_loss(grad_lon_pred, grad_lon_true, reduction='sum')

    # 3. Multi-scale analysis (weather has features at different spatial scales)
    scale = 2  # Downsample factor
    x_down = F.avg_pool3d(x, kernel_size=(1, scale, scale))
    recon_x_down = F.avg_pool3d(recon_x, kernel_size=(1, scale, scale))
    mask_down = F.avg_pool3d(mask, kernel_size=(1, scale, scale))

    inv_mask_down = 1 - mask_down
    scale_mse = F.mse_loss(recon_x_down * inv_mask_down, x_down * inv_mask_down, reduction='sum')

    # 4. KL divergence (standard from VAE)
    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())

    # Final combined loss with weights
    total_loss = (
        loss_weights['reconstruction'] * masked_mse +
        loss_weights['gradient'] * (grad_lat_loss + grad_lon_loss) +
        loss_weights['multiscale'] * scale_mse
    ) / batch_size + loss_weights['kl'] * kl_loss / batch_size

    # For tracking individual components (normalized)
    loss_components = {
        'total': total_loss.item(),
        'reconstruction': (masked_mse / batch_size).item(),
        'gradient': ((grad_lat_loss + grad_lon_loss) / batch_size).item(),
        'multiscale': (scale_mse / batch_size).item(),
        'kl': (kl_loss / batch_size).item()
    }

    return total_loss, loss_components


class WeatherTrainer:
    """
    Trainer class for Weather DVAE models
    """

    def __init__(self, model, optimizer, loss_fn=None, device=None, scheduler=None):
        """
        Initialize trainer

        Args:
            model: The model to train
            optimizer: Optimizer for training
            loss_fn: Loss function (if None, use weather_dvae_loss)
            device: Device to train on (if None, use 'cuda' if available else 'cpu')
            scheduler: Optional learning rate scheduler
        """
        self.model = model
        self.optimizer = optimizer
        self.loss_fn = loss_fn if loss_fn else weather_dvae_loss
        self.device = device if device else torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.scheduler = scheduler

        # History for tracking metrics
        self.history = {
            'train_loss': [],
            'val_loss': [],
            'loss_components': []
        }

    def train_epoch(self, dataloader):
        """
        Train for one epoch

        Args:
            dataloader: DataLoader with training data

        Returns:
            dict: Metrics from this epoch
        """
        self.model.train()
        epoch_loss = 0
        epoch_components = {'reconstruction': 0, 'gradient': 0, 'multiscale': 0, 'kl': 0}
        num_batches = len(dataloader)

        for batch in dataloader:
            original = batch['original'].to(self.device)
            corrupted = batch['corrupted'].to(self.device)
            mask = batch['mask'].to(self.device)

            self.optimizer.zero_grad()

            # Forward pass
            recon_batch, mu, logvar = self.model(corrupted, mask)

            # Ensure shapes match before calculating loss
            if recon_batch.shape != original.shape:
                recon_batch = F.interpolate(
                    recon_batch,
                    size=original.shape[2:],
                    mode='trilinear',
                    align_corners=False
                )

            # Calculate loss
            loss, components = self.loss_fn(recon_batch, original, mu, logvar, mask)

            # Backward pass
            loss.backward()
            self.optimizer.step()

            # Track metrics
            epoch_loss += loss.item()
            for k, v in components.items():
                if k != 'total':
                    epoch_components[k] += v

        # NOTE: Removed scheduler step from here
        # It's moved to the train method to use validation loss

        # Calculate averages
        avg_loss = epoch_loss / num_batches
        avg_components = {k: v / num_batches for k, v in epoch_components.items()}

        metrics = {
            'loss': avg_loss,
            'components': avg_components
        }

        # Update history
        self.history['train_loss'].append(avg_loss)
        self.history['loss_components'].append(avg_components)

        return metrics

    def train(self, train_loader, val_loader=None, num_epochs=10,
              save_path=None, save_freq=5, early_stopping=None):
        """
        Train the model for multiple epochs

        Args:
            train_loader: DataLoader with training data
            val_loader: Optional DataLoader with validation data
            num_epochs: Number of epochs to train
            save_path: Optional path to save checkpoints
            save_freq: Frequency (in epochs) to save checkpoints
            early_stopping: Number of epochs to wait before stopping if no improvement

        Returns:
            dict: Training history
        """
        best_val_loss = float('inf')
        no_improve_count = 0

        for epoch in range(num_epochs):
            # Train for one epoch
            train_metrics = self.train_epoch(train_loader)

            # Validate if validation data is provided
            if val_loader is not None:
                val_metrics = self.validate(val_loader)
                current_val_loss = val_metrics['loss']

                # Step scheduler if it's ReduceLROnPlateau
                if self.scheduler is not None:
                    if isinstance(self.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):
                        self.scheduler.step(current_val_loss)
                    else:
                        self.scheduler.step()

                # Check for improvement (for early stopping)
                if current_val_loss < best_val_loss:
                    best_val_loss = current_val_loss
                    no_improve_count = 0

                    # Save best model
                    if save_path is not None:
                        self.save_checkpoint(f"{save_path}_best.pt")
                else:
                    no_improve_count += 1

                # Print progress
                print(f"Epoch {epoch+1}/{num_epochs} - "
                      f"Train Loss: {train_metrics['loss']:.4f}, "
                      f"Val Loss: {val_metrics['loss']:.4f}")
            else:
                # If no validation loader, use training loss for scheduler
                if self.scheduler is not None:
                    if isinstance(self.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):
                        self.scheduler.step(train_metrics['loss'])
                    else:
                        self.scheduler.step()

                # Print progress without validation
                print(f"Epoch {epoch+1}/{num_epochs} - "
                      f"Train Loss: {train_metrics['loss']:.4f}")

            # Save checkpoint periodically if requested
            if save_path is not None and (epoch + 1) % save_freq == 0:
                self.save_checkpoint(f"{save_path}_epoch{epoch+1}.pt")

            # Early stopping check
            if early_stopping is not None and no_improve_count >= early_stopping:
                print(f"Early stopping triggered after {epoch+1} epochs")
                break

        # Save final model
        if save_path is not None:
            self.save_checkpoint(f"{save_path}_final.pt")

        return self.history

    def validate(self, dataloader):
        """
        Validate the model

        Args:
            dataloader: DataLoader with validation data

        Returns:
            dict: Validation metrics
        """
        self.model.eval()
        val_loss = 0
        val_components = {'reconstruction': 0, 'gradient': 0, 'multiscale': 0, 'kl': 0}
        num_batches = len(dataloader)

        with torch.no_grad():
            for batch in dataloader:
                original = batch['original'].to(self.device)
                corrupted = batch['corrupted'].to(self.device)
                mask = batch['mask'].to(self.device)

                # Forward pass
                recon_batch, mu, logvar = self.model(corrupted, mask)

                # Ensure shapes match
                if recon_batch.shape != original.shape:
                    recon_batch = F.interpolate(
                        recon_batch,
                        size=original.shape[2:],
                        mode='trilinear',
                        align_corners=False
                    )

                # Calculate loss
                loss, components = self.loss_fn(recon_batch, original, mu, logvar, mask)

                # Track metrics
                val_loss += loss.item()
                for k, v in components.items():
                    if k != 'total':
                        val_components[k] += v

        # Calculate averages
        avg_loss = val_loss / num_batches
        avg_components = {k: v / num_batches for k, v in val_components.items()}

        metrics = {
            'loss': avg_loss,
            'components': avg_components
        }

        # Update history
        self.history['val_loss'].append(avg_loss)

        return metrics

    def save_checkpoint(self, path):
        """
        Save model checkpoint

        Args:
            path: Path to save checkpoint
        """
        checkpoint = {
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'history': self.history
        }

        # Add scheduler state if it exists
        if self.scheduler is not None:
            checkpoint['scheduler_state_dict'] = self.scheduler.state_dict()

        torch.save(checkpoint, path)
        print(f"Checkpoint saved to {path}")

    def load_checkpoint(self, path):
        """
        Load model checkpoint

        Args:
            path: Path to checkpoint
        """
        checkpoint = torch.load(path, map_location=self.device)

        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])

        # Load scheduler if it exists in checkpoint and we have one
        if 'scheduler_state_dict' in checkpoint and self.scheduler is not None:
            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])

        # Load history if it exists
        if 'history' in checkpoint:
            self.history = checkpoint['history']

        print(f"Checkpoint loaded from {path}")

# @title CIRRUS: Evaluation Module

class WeatherEvaluator:
    """
    Class for evaluating Weather DVAE models
    """
    def __init__(self, model=None, device=None):
        """
        Initialize evaluator
        Args:
            model: Trained model to evaluate (can be None for some methods)
            device: Device to use for evaluation
        """
        self.model = model
        self.device = device if device else torch.device("cuda" if torch.cuda.is_available() else "cpu")
        if self.model is not None:
            self.model.to(self.device)

    def evaluate_reconstruction(self, test_loader, denormalize_fn=None):
        """
        Evaluate model reconstruction metrics
        Args:
            test_loader: DataLoader with test data
            denormalize_fn: Optional function to denormalize data for metrics
        Returns:
            dict: Dictionary of evaluation metrics
        """
        all_metrics = {
            'rmse': [],
            'mae': [],
            'ssim': [],
            'gradient_rmse': [],
            'explained_variance': [],
            'kl_div': []
        }
        with torch.no_grad():
            for batch in test_loader:
                original = batch['original'].to(self.device)
                corrupted = batch['corrupted'].to(self.device)
                mask = batch['mask'].to(self.device)
                recon, mu, logvar = self.model(corrupted, mask)
                if recon.shape != original.shape:
                    recon = F.interpolate(
                        recon,
                        size=original.shape[2:],
                        mode='trilinear',
                        align_corners=False
                    )
                inv_mask = 1 - mask

                recon = torch.clamp(recon, -3.0, 3.0)
                if denormalize_fn:
                    masked_original_np = denormalize_fn(original * inv_mask).cpu().numpy()
                    masked_recon_np = denormalize_fn(recon * inv_mask).cpu().numpy()
                else:
                    masked_original_np = (original * inv_mask).cpu().numpy()
                    masked_recon_np = (recon * inv_mask).cpu().numpy()
                for i in range(original.size(0)):
                    mse = F.mse_loss(recon[i] * inv_mask[i], original[i] * inv_mask[i], reduction='mean').item()
                    all_metrics['rmse'].append(np.sqrt(mse))
                    mae = F.l1_loss(recon[i] * inv_mask[i], original[i] * inv_mask[i], reduction='mean').item()
                    all_metrics['mae'].append(mae)
                    ssim_scores = []
                    for c in range(original.size(1)):
                        for l in range(original.size(2)):
                            orig_2d = masked_original_np[i, c, l].squeeze()
                            recon_2d = masked_recon_np[i, c, l].squeeze()
                            if np.std(orig_2d) == 0 or np.std(recon_2d) == 0:
                                continue
                            data_range = orig_2d.max() - orig_2d.min()
                            if data_range > 0:
                                ssim_val = ssim(orig_2d, recon_2d, data_range=data_range)
                                ssim_scores.append(ssim_val)
                    if ssim_scores:
                        all_metrics['ssim'].append(np.mean(ssim_scores))
                    grad_lat_true = original[i, :, :, 1:, :] - original[i, :, :, :-1, :]
                    grad_lon_true = original[i, :, :, :, 1:] - original[i, :, :, :, :-1]
                    grad_lat_pred = recon[i, :, :, 1:, :] - recon[i, :, :, :-1, :]
                    grad_lon_pred = recon[i, :, :, :, 1:] - recon[i, :, :, :, :-1]
                    lat_mse = F.mse_loss(grad_lat_pred, grad_lat_true).item()
                    lon_mse = F.mse_loss(grad_lon_pred, grad_lon_true).item()
                    all_metrics['gradient_rmse'].append(np.sqrt((lat_mse + lon_mse) / 2))
                    orig_flat = masked_original_np[i].flatten()
                    recon_flat = masked_recon_np[i].flatten()
                    mask_indices = orig_flat != 0
                    if np.any(mask_indices):
                        r2 = r2_score(orig_flat[mask_indices], recon_flat[mask_indices])
                        all_metrics['explained_variance'].append(max(0, r2))
                    kl = -0.5 * torch.sum(1 + logvar[i] - mu[i].pow(2) - logvar[i].exp()).item()
                    all_metrics['kl_div'].append(kl)
        avg_metrics = {k: np.mean(v) for k, v in all_metrics.items() if v}
        return avg_metrics

    def get_reconstructions(self, dataset, num_samples=5, denormalize_fn=None):
        """
        Get sample reconstructions from the model
        Args:
            dataset: Dataset to sample from
            num_samples: Number of samples to reconstruct
            denormalize_fn: Optional function to denormalize data
        Returns:
            tuple: (original, corrupted, reconstructed) arrays
        """
        loader = DataLoader(dataset, batch_size=num_samples, shuffle=True)
        batch = next(iter(loader))
        with torch.no_grad():
            original = batch['original'].to(self.device)
            corrupted = batch['corrupted'].to(self.device)
            mask = batch['mask'].to(self.device)
            recon, _, _ = self.model(corrupted, mask)
            if recon.shape != original.shape:
                recon = F.interpolate(
                    recon,
                    size=original.shape[2:],
                    mode='trilinear',
                    align_corners=False
                )
            if denormalize_fn:
                original = denormalize_fn(original)
                corrupted = denormalize_fn(corrupted)
                recon = denormalize_fn(recon)
            original = original.cpu().numpy()
            corrupted = corrupted.cpu().numpy()
            recon = recon.cpu().numpy()
        return original, corrupted, recon

    def visualize_reconstructions(self, original, corrupted, recon, level_idx=None, sparsity=None, channel_idx=0,
                             grid_coords=None, projection=None):
        """
        Visualize original, corrupted, and reconstructed samples with map projections
        Args:
            original: Original data array
            corrupted: Corrupted data array with masking applied
            recon: Reconstructed data array from the model
            level_idx: Pressure level index to visualize (if None, creates plots for both levels)
            sparsity: Sparsity level (for title)
            channel_idx: Channel index for visualization (if None, creates plots for both channels)
            grid_coords: Dictionary with 'lats' and 'lons' coordinates (if None, uses indices)
            projection: Cartopy projection to use for mapping (if None, uses simpler approach)
        Returns:
            matplotlib.figure.Figure: Figure with visualizations
        """
        # Check the shape of the arrays
        print(f"Reconstructions - Original shape: {original.shape}, Corrupted shape: {corrupted.shape}, Recon shape: {recon.shape}")

        # If original has 3 or more dimensions, we can iterate through levels
        if level_idx is None and len(original.shape) >= 3:
            figures = []
            num_levels = original.shape[2] if len(original.shape) >= 3 else 1
            for idx in range(num_levels):  # Iterate through all levels
                fig = self.visualize_reconstructions(
                    original, corrupted, recon,
                    level_idx=idx, sparsity=sparsity,
                    channel_idx=channel_idx, grid_coords=grid_coords,
                    projection=projection)
                figures.append(fig)
            return figures

        # If channel_idx is None and we have a channel dimension, visualize all channels
        if channel_idx is None and len(original.shape) >= 3 and original.shape[1] > 1:
            figures = []
            for idx in range(original.shape[1]):  # Iterate through all channels
                fig = self.visualize_reconstructions(
                    original, corrupted, recon,
                    level_idx=level_idx, sparsity=sparsity,
                    channel_idx=idx, grid_coords=grid_coords,
                    projection=projection)
                figures.append(fig)
            return figures

        # Determine if we should use cartopy projections
        use_cartopy = projection is not None and projection != 'none'
        num_samples = original.shape[0]

        # Create figure with or without cartopy subplot keyword
        if use_cartopy:
            fig, axes = plt.subplots(num_samples, 3, figsize=(18, 5*num_samples),
                                    subplot_kw={'projection': projection})
        else:
            fig, axes = plt.subplots(num_samples, 3, figsize=(18, 5*num_samples))

        # Add appropriate title
        channel_info = f"Channel {channel_idx+1}" if channel_idx is not None else ""
        level_info = f"Level {level_idx+1}" if level_idx is not None else ""
        if sparsity is not None:
            title_parts = [f"Reconstruction Results with {int(sparsity*100)}% Sparsity"]
            if level_info:
                title_parts.append(level_info)
            if channel_info:
                title_parts.append(channel_info)
            fig.suptitle(" - ".join(title_parts), fontsize=16, y=0.98)

        # Set up coordinate grid
        if grid_coords is None:
            # Determine grid sizes from data shapes
            if len(original.shape) >= 3:
                # For multi-dimensional data
                lat_size = original.shape[-2] if len(original.shape) >= 4 else original.shape[-1]
                lon_size = original.shape[-1] if len(original.shape) >= 4 else original.shape[-1]
            else:
                # For 2D data
                lat_size = original.shape[1]
                lon_size = original.shape[2] if len(original.shape) > 2 else original.shape[1]

            lats = np.linspace(-90, 90, lat_size)
            lons = np.linspace(0, 360, lon_size, endpoint=False)
        else:
            lats = grid_coords['lats']
            lons = grid_coords['lons']

        lon_mesh, lat_mesh = np.meshgrid(lons, lats)

        def robust_minmax(data, percentile=1):
            flat_data = data.reshape(-1)
            lower = np.percentile(flat_data, percentile)
            upper = np.percentile(flat_data, 100 - percentile)
            return lower, upper

        # Extract data for visualization
        if len(original.shape) >= 3 and original.shape[1] > 1:
            # We have separate channel dimension
            orig_data = original[:, channel_idx, level_idx]
            corr_data = corrupted[:, channel_idx, level_idx]
            recon_data = recon[:, channel_idx, level_idx]
        else:
            # No separate channel dimension or single channel
            if len(original.shape) >= 3:
                orig_data = original[:, 0, level_idx] if original.shape[1] == 1 else original[:, level_idx]
                corr_data = corrupted[:, 0, level_idx] if corrupted.shape[1] == 1 else corrupted[:, level_idx]
                recon_data = recon[:, 0, level_idx] if recon.shape[1] == 1 else recon[:, level_idx]
            else:
                orig_data = original
                corr_data = corrupted
                recon_data = recon

        # Calculate global min/max for consistent colormap
        try:
            all_data = np.concatenate([orig_data.flatten(), recon_data.flatten()])
            data_min, data_max = robust_minmax(all_data)
            contour_levels = np.linspace(data_min, data_max, 20)
        except Exception as e:
            print(f"Error calculating data range: {e}")
            # Fallback to separate min/max
            data_min = min(np.nanmin(orig_data), np.nanmin(recon_data))
            data_max = max(np.nanmax(orig_data), np.nanmax(recon_data))
            contour_levels = np.linspace(data_min, data_max, 20)

        colormap = cm.jet  # Set colormap to jet

        # Handle single sample case
        if num_samples == 1 and len(axes.shape) < 2:
            axes = np.array([axes])

        # Plot the data
        for i in range(num_samples):
            if num_samples == 1:
                ax_row = axes
            else:
                ax_row = axes[i] if len(axes.shape) > 1 else axes

            # Get the data for this sample
            if len(orig_data.shape) > 2:  # If we have a batch dimension
                sample_orig = orig_data[i]
                sample_corr = corr_data[i]
                sample_recon = recon_data[i]
            else:
                sample_orig = orig_data
                sample_corr = corr_data
                sample_recon = recon_data

            # Plot original
            ax = ax_row[0] if len(ax_row) > 0 else ax_row
            if use_cartopy:
                try:
                    contour = ax.contourf(lon_mesh, lat_mesh, sample_orig,
                                        transform=ccrs.PlateCarree(),
                                        cmap=colormap, levels=contour_levels, extend='both')
                    try:
                        ax.coastlines(resolution='110m', color='black', linewidth=0.5)
                    except:
                        pass  # Skip coastlines if they cause problems
                    ax.gridlines(draw_labels=True, linewidth=0.5, color='gray', alpha=0.5, linestyle='--')
                except Exception as e:
                    print(f"Error with cartopy plot: {e}")
                    # Fallback to simple imshow
                    contour = ax.imshow(sample_orig, cmap=colormap, aspect='auto')
                    ax.grid(False)
            else:
                contour = ax.imshow(sample_orig, cmap=colormap, aspect='auto')
                ax.grid(True, linestyle='--', alpha=0.3)

            ax.set_title('Original')
            plt.colorbar(contour, ax=ax, orientation='horizontal', pad=0.05, shrink=0.8)

            # Plot corrupted
            ax = ax_row[1] if len(ax_row) > 1 else ax_row
            if use_cartopy:
                try:
                    contour = ax.contourf(lon_mesh, lat_mesh, sample_corr,
                                        transform=ccrs.PlateCarree(),
                                        cmap=colormap, levels=contour_levels, extend='both')
                    try:
                        ax.coastlines(resolution='110m', color='black', linewidth=0.5)
                    except:
                        pass  # Skip coastlines if they cause problems
                    ax.gridlines(draw_labels=True, linewidth=0.5, color='gray', alpha=0.5, linestyle='--')
                except Exception as e:
                    print(f"Error with cartopy plot: {e}")
                    # Fallback to simple imshow
                    contour = ax.imshow(sample_corr, cmap=colormap, aspect='auto')
                    ax.grid(False)
            else:
                contour = ax.imshow(sample_corr, cmap=colormap, aspect='auto')
                ax.grid(True, linestyle='--', alpha=0.3)

            ax.set_title('Corrupted')
            plt.colorbar(contour, ax=ax, orientation='horizontal', pad=0.05, shrink=0.8)

            # Plot reconstructed
            ax = ax_row[2] if len(ax_row) > 2 else ax_row
            if use_cartopy:
                try:
                    contour = ax.contourf(lon_mesh, lat_mesh, sample_recon,
                                        transform=ccrs.PlateCarree(),
                                        cmap=colormap, levels=contour_levels, extend='both')
                    try:
                        ax.coastlines(resolution='110m', color='black', linewidth=0.5)
                    except:
                        pass  # Skip coastlines if they cause problems
                    ax.gridlines(draw_labels=True, linewidth=0.5, color='gray', alpha=0.5, linestyle='--')
                except Exception as e:
                    print(f"Error with cartopy plot: {e}")
                    # Fallback to simple imshow
                    contour = ax.imshow(sample_recon, cmap=colormap, aspect='auto')
                    ax.grid(False)
            else:
                contour = ax.imshow(sample_recon, cmap=colormap, aspect='auto')
                ax.grid(True, linestyle='--', alpha=0.3)

            ax.set_title('Reconstructed')
            plt.colorbar(contour, ax=ax, orientation='horizontal', pad=0.05, shrink=0.8)

        plt.tight_layout()
        return fig

    def visualize_error_map(self, original, recon, level_idx=None, channel_idx=None,
                        grid_coords=None, projection=ccrs.PlateCarree()):
        """
        Create visualization of reconstruction error map with map projections
        Args:
            original: Original data array
            recon: Reconstructed data array
            level_idx: Pressure level index to visualize (if None, creates plots for both levels)
            channel_idx: Channel index for visualization (if None, creates plots for both channels)
            grid_coords: Dictionary with 'lats' and 'lons' coordinates (if None, uses indices)
            projection: Cartopy projection to use for mapping
        Returns:
            matplotlib.figure.Figure: Figure with error maps
        """
        # If level_idx is None, visualize both levels separately
        # Check the shape of the arrays
        print(f"Error map - Original shape: {original.shape}, Recon shape: {recon.shape}")

        # If original has 3 or more dimensions, we can iterate through levels
        if level_idx is None and len(original.shape) >= 3:
            figures = []
            num_levels = original.shape[2] if len(original.shape) >= 3 else 1
            for idx in range(num_levels):  # Iterate through all levels
                fig = self.visualize_error_map(
                    original, recon,
                    level_idx=idx, channel_idx=channel_idx,
                    grid_coords=grid_coords, projection=projection)
                figures.append(fig)
            return figures

        # If channel_idx is None and we have a channel dimension, visualize all channels
        if channel_idx is None and len(original.shape) >= 3 and original.shape[1] > 1:
            figures = []
            for idx in range(original.shape[1]):  # Iterate through all channels
                fig = self.visualize_error_map(
                    original, recon,
                    level_idx=level_idx, channel_idx=idx,
                    grid_coords=grid_coords, projection=projection)
                figures.append(fig)
            return figures

        num_samples = original.shape[0]
        fig, axes = plt.subplots(num_samples, 3, figsize=(18, 5*num_samples),
                                subplot_kw={'projection': projection})

        fig.suptitle(f"Reconstruction Error Analysis - Level {level_idx+1} - Channel {channel_idx+1}",
                    fontsize=16, y=0.98)

        if grid_coords is None:
            lat_size = original.shape[3]
            lon_size = original.shape[4]
            lats = np.linspace(-90, 90, lat_size)
            lons = np.linspace(0, 360, lon_size)
        else:
            lats = grid_coords['lats']
            lons = grid_coords['lons']

        lon_mesh, lat_mesh = np.meshgrid(lons, lats)

        for i in range(num_samples):
            if num_samples == 1:
                ax_row = axes
            else:
                ax_row = axes[i]

            ax = ax_row[0]

            # Get the data based on the shape of the arrays
            if len(original.shape) >= 3 and original.shape[1] > 1:
                # We have separate channel dimension
                orig_data = original[i, channel_idx, level_idx]
                recon_data = recon[i, channel_idx, level_idx]
            else:
                # No separate channel dimension or single channel
                orig_data = original[i, 0, level_idx] if len(original.shape) >= 3 else original[i, level_idx]
                recon_data = recon[i, 0, level_idx] if len(recon.shape) >= 3 else recon[i, level_idx]

            data_min = np.min(orig_data)
            data_max = np.max(orig_data)
            contour_levels = np.linspace(data_min, data_max, 20)

            contour = ax.contourf(lon_mesh, lat_mesh, orig_data,
                                transform=ccrs.PlateCarree(),
                                cmap=cm.jet, levels=contour_levels, extend='both')
            ax.coastlines(resolution='50m', color='black', linewidth=0.5)
            ax.gridlines(draw_labels=True, linewidth=0.5, color='gray', alpha=0.5, linestyle='--')
            ax.set_title('Original')
            plt.colorbar(contour, ax=ax, orientation='horizontal', pad=0.05, shrink=0.8)

            ax = ax_row[1]
            contour = ax.contourf(lon_mesh, lat_mesh, recon_data,
                                transform=ccrs.PlateCarree(),
                                cmap=cm.jet, levels=contour_levels, extend='both')
            ax.coastlines(resolution='50m', color='black', linewidth=0.5)
            ax.gridlines(draw_labels=True, linewidth=0.5, color='gray', alpha=0.5, linestyle='--')
            ax.set_title('Reconstructed')
            plt.colorbar(contour, ax=ax, orientation='horizontal', pad=0.05, shrink=0.8)

            ax = ax_row[2]
            error = np.abs(orig_data - recon_data)

            error_max = np.max(error)
            contour_levels_error = np.linspace(0, error_max, 20)

            contour = ax.contourf(lon_mesh, lat_mesh, error,
                                transform=ccrs.PlateCarree(),
                                cmap='hot', levels=contour_levels_error, extend='max')
            ax.coastlines(resolution='50m', color='black', linewidth=0.5)
            ax.gridlines(draw_labels=True, linewidth=0.5, color='gray', alpha=0.5, linestyle='--')
            ax.set_title('Absolute Error')
            plt.colorbar(contour, ax=ax, orientation='horizontal', pad=0.05, shrink=0.8)

        plt.tight_layout()
        return fig

    def compare_sparsity_levels(self, metrics_by_sparsity):
        """
        Create visualizations comparing metrics across sparsity levels
        Args:
            metrics_by_sparsity: Dictionary mapping sparsity levels to metrics
        Returns:
            matplotlib.figure.Figure: Figure with performance comparisons
        """
        if len(metrics_by_sparsity) < 1:
            fig, ax = plt.subplots(figsize=(10, 8))
            ax.text(0.5, 0.5, "Not enough data to compare sparsity levels",
                    horizontalalignment='center', verticalalignment='center',
                    fontsize=14)
            ax.axis('off')
            return fig

        sparsity_levels = sorted(metrics_by_sparsity.keys())
        metrics_to_plot = ['rmse', 'ssim', 'explained_variance', 'gradient_rmse']

        available_metrics = []
        for metric in metrics_to_plot:
            if all(metric in metrics_by_sparsity[sl] for sl in sparsity_levels):
                available_metrics.append(metric)

        if not available_metrics:
            fig, ax = plt.subplots(figsize=(10, 8))
            ax.text(0.5, 0.5, "No common metrics available across sparsity levels",
                    horizontalalignment='center', verticalalignment='center',
                    fontsize=14)
            ax.axis('off')
            return fig

        if len(available_metrics) <= 2:
            fig, axes = plt.subplots(1, len(available_metrics), figsize=(6*len(available_metrics), 5))
            if len(available_metrics) == 1:
                axes = [axes]
        else:
            nrows = (len(available_metrics) + 1) // 2
            fig, axes = plt.subplots(nrows, 2, figsize=(12, 5*nrows))
            axes = axes.flatten()

        line_color = '#1f77b4'  # Blue
        marker_color = '#ff7f0e'  # Orange
        grid_color = '#cccccc'  # Light gray

        for i, metric in enumerate(available_metrics):
            values = [metrics_by_sparsity[sl][metric] for sl in sparsity_levels]

            axes[i].plot(
                [sl * 100 for sl in sparsity_levels],
                values, 'o-', linewidth=2,
                color=line_color,
                markersize=8,
                markerfacecolor=marker_color,
                markeredgecolor='black',
                markeredgewidth=1
            )

            axes[i].set_xlabel('Sparsity Level (%)', fontsize=12)
            axes[i].set_ylabel(metric.replace('_', ' ').title(), fontsize=12)
            axes[i].set_title(f'{metric.replace("_", " ").title()} vs Sparsity', fontsize=14)

            axes[i].grid(True, linestyle='--', linewidth=0.7, color=grid_color)
            axes[i].set_axisbelow(True)

            for x, y in zip([sl * 100 for sl in sparsity_levels], values):
                axes[i].annotate(
                    f'{y:.3f}',
                    (x, y),
                    textcoords="offset points",
                    xytext=(0, 10),
                    ha='center',
                    fontsize=10,
                    bbox=dict(
                        boxstyle="round,pad=0.3",
                        fc="white",
                        ec="gray",
                        alpha=0.9,
                        linewidth=1
                    )
                )

        for j in range(len(available_metrics), len(axes)):
            axes[j].axis('off')

        plt.tight_layout()
        return fig

    def visualize_spatial_patterns(self, data, time_steps=None, channels=None,
                                lats=None, lons=None, projection=ccrs.PlateCarree()):
        """
        Plot spatial patterns for different time steps and channels with map projections
        Args:
            data: Data array with dimensions [time, channel, lat, lon]
            time_steps: List of time indices to plot (default: first few time steps)
            channels: List of channel indices to plot (default: all channels)
            lats: Latitude coordinates (default: creates evenly spaced coordinates)
            lons: Longitude coordinates (default: creates evenly spaced coordinates)
            projection: Cartopy projection to use for mapping
        Returns:
            matplotlib.figure.Figure: Figure with spatial patterns
        """
        if time_steps is None:
            time_steps = [0, 4, 8] if data.shape[0] > 8 else list(range(min(3, data.shape[0])))

        if channels is None:
            channels = list(range(data.shape[1]))

        if lats is None:
            lats = np.linspace(-90, 90, data.shape[2])

        if lons is None:
            lons = np.linspace(0, 360, data.shape[3])

        lon_mesh, lat_mesh = np.meshgrid(lons, lats)

        fig = plt.figure(figsize=(15, 10))

        data_min = np.nanmin(data)
        data_max = np.nanmax(data)
        contour_levels = np.linspace(data_min, data_max, 20)

        for i, time_step in enumerate(time_steps):
            for j, channel in enumerate(channels):
                idx = i * len(channels) + j + 1

                ax = fig.add_subplot(len(time_steps), len(channels), idx,
                                    projection=projection)

                if time_step >= data.shape[0] or channel >= data.shape[1]:
                    ax.text(0.5, 0.5, "Index out of range",
                        horizontalalignment='center',
                        verticalalignment='center',
                        transform=ax.transAxes)
                    continue

                contour = ax.contourf(lon_mesh, lat_mesh, data[time_step, channel],
                                    transform=ccrs.PlateCarree(),
                                    cmap=cm.jet, levels=contour_levels, extend='both')

                ax.coastlines(resolution='50m', color='black', linewidth=0.5)

                gl = ax.gridlines(draw_labels=True, linewidth=0.5,
                                color='gray', alpha=0.5, linestyle='--')
                gl.top_labels = False
                gl.right_labels = False

                time_info = f'Time: {time_step}'
                if hasattr(data, 'time_hours') and len(data.time_hours) > time_step:
                    time_info = f'Time: {data.time_hours[time_step]}h'

                ax.set_title(f'{time_info} (Channel: {channel})')

                plt.colorbar(contour, ax=ax, shrink=0.7)

        plt.tight_layout()
        return fig

# @title CIRRUS: Visualization Module

class ModelVisualizer:
    """
    Class for visualizing model architecture and training progress
    """

    @staticmethod
    def plot_training_history(history):
        """
        Plot training history metrics

        Args:
            history: Dictionary containing training metrics

        Returns:
            matplotlib.figure.Figure: Figure with training plots
        """
        fig, axes = plt.subplots(1, 2, figsize=(15, 5))

        epochs = range(1, len(history['train_loss']) + 1)

        axes[0].plot(epochs, history['train_loss'], 'b-', label='Training Loss')
        if 'val_loss' in history and history['val_loss']:
            axes[0].plot(epochs, history['val_loss'], 'r-', label='Validation Loss')

        axes[0].set_title('Loss')
        axes[0].set_xlabel('Epoch')
        axes[0].set_ylabel('Loss')
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)
        axes[0].set_yscale('log')

        if 'loss_components' in history and history['loss_components']:
            components = {}
            for epoch_components in history['loss_components']:
                for key, value in epoch_components.items():
                    if key not in components:
                        components[key] = []
                    components[key].append(value)

            for key, values in components.items():
                axes[1].plot(epochs, values, label=key.capitalize())

            axes[1].set_title('Loss Components')
            axes[1].set_xlabel('Epoch')
            axes[1].set_ylabel('Value')
            axes[1].legend()
            axes[1].grid(True, alpha=0.3)
            axes[1].set_yscale('log')

        plt.tight_layout()
        return fig

    @staticmethod
    def visualize_latent_space(model, dataset, n_samples=500, device=None):
        """
        Visualize the learned latent space

        Args:
            model: Trained model
            dataset: Dataset to sample from
            n_samples: Number of samples to use
            device: Device to use for computation

        Returns:
            matplotlib.figure.Figure: Figure with latent space visualization
        """
        if device is None:
            device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        loader = DataLoader(dataset, batch_size=n_samples, shuffle=True)
        batch = next(iter(loader))

        original = batch['original'].to(device)
        corrupted = batch['corrupted'].to(device)
        mask = batch['mask'].to(device)

        model.eval()
        with torch.no_grad():
            mu, logvar = model.encode(corrupted, mask)
            latent_samples = model.reparameterize(mu, logvar)

            from sklearn.manifold import TSNE
            tsne = TSNE(n_components=2, random_state=42)

            latent_2d = tsne.fit_transform(latent_samples.cpu().numpy())

        # Create plot
        fig, ax = plt.subplots(figsize=(10, 8))
        scatter = ax.scatter(latent_2d[:, 0], latent_2d[:, 1], c=range(n_samples),
                            cmap='viridis', alpha=0.6, s=20)

        plt.colorbar(scatter, label='Sample Index')
        ax.set_title('t-SNE Visualization of Latent Space', fontsize=14)
        ax.set_xlabel('t-SNE Dimension 1', fontsize=12)
        ax.set_ylabel('t-SNE Dimension 2', fontsize=12)
        ax.grid(True, alpha=0.3)

        plt.tight_layout()
        return fig

def safe_projection():
    """
    Create a safe map projection that avoids GeometryCollection errors

    Returns:
        A projection object that can be used for mapping
    """
    # Use a simpler Robinson projection instead of PlateCarree
    # which tends to have fewer issues with complex geometries
    projection = ccrs.Robinson(central_longitude=180)
    return projection

# For CIRRUS visualize_reconstructions
def add_coastlines_safely(ax):
    """Safely add coastlines to avoid GeometryCollection errors"""
    try:
        # Try with lower resolution first
        ax.coastlines(resolution='110m', color='black', linewidth=0.5)
    except (TypeError, ValueError):
        try:
            # If that fails, try an even simpler approach
            ax.coastlines(resolution='110m', color='black', linewidth=0.5, scale='110m')
        except:
            # If all else fails, just skip coastlines
            print("Warning: Unable to add coastlines to map")
            pass

# For plotting without using cartopy
def simple_plot_without_cartopy(fig, axes, data, title, colormap='jet', levels=20):
    """
    Create a simple plot without using Cartopy to avoid GeometryCollection errors

    Args:
        fig: Figure object
        axes: Axes object
        data: 2D array to plot
        title: Title for the plot
        colormap: Colormap to use
        levels: Number of contour levels
    """
    contour = axes.imshow(data, cmap=colormap, interpolation='none')
    axes.set_title(title)
    plt.colorbar(contour, ax=axes, orientation='horizontal', pad=0.05, shrink=0.8)
    axes.set_xlabel('Longitude')
    axes.set_ylabel('Latitude')
    axes.grid(True, linestyle='--', alpha=0.3)
    return contour

# @title CIRRUS: Experiment Module

class WeatherExperiment:
    """
    Class for running experiments with different model configurations
    """

    def __init__(self, data_path, years_train, years_test, device=None):
        """
        Initialize experiment

        Args:
            data_path: Path to data directory
            years_train: List of years for training
            years_test: List of years for testing
            device: Device to use for computation
        """
        self.data_path = data_path
        self.years_train = years_train
        self.years_test = years_test
        self.device = device if device else torch.device("cuda" if torch.cuda.is_available() else "cpu")

        self.train_files = [os.path.join(data_path, f'z{year}.nc') for year in years_train]
        self.test_files = [os.path.join(data_path, f'z{year}.nc') for year in years_test]

        self.results = {}

    def run_sparsity_experiment(self, sparsity_levels, epochs, batch_size=32,
                              latent_dim=128, save_dir='./models'):
        """
        Run experiment with different sparsity levels

        Args:
            sparsity_levels: List of sparsity ratios to test
            epochs: Number of epochs for training
            batch_size: Batch size for training
            latent_dim: Latent dimension for the model
            save_dir: Directory to save models and results

        Returns:
            dict: Results dictionary
        """
        os.makedirs(save_dir, exist_ok=True)

        self.results = {
            'models': {},
            'metrics': {},
            'history': {}
        }

        aug_config = {
            'circular_shift': True,
            'vertical_flip': False,
            'noise_injection': False,
            'shift_prob': 0.5,
            'flip_prob': 0.3,
            'noise_prob': 0.3,
            'noise_scale': 0.05,
            'max_shift_percent': 0.5
        }

        for sparsity in sparsity_levels:
            print(f"\n{'='*80}")
            print(f"Starting experiment with sparsity level: {sparsity:.1%}")
            print(f"{'='*80}")

            train_dataset = WeatherDataset(
                self.train_files,
                is_training=True,
                sparsity_ratio=sparsity,
                augmentation_config=aug_config
            )

            test_dataset = WeatherDataset(
                self.test_files,
                is_training=False,
                sparsity_ratio=sparsity
            )

            train_loader = DataLoader(
                train_dataset,
                batch_size=batch_size,
                shuffle=True
            )

            test_loader = DataLoader(
                test_dataset,
                batch_size=batch_size,
                shuffle=False
            )

            model = WeatherDVAE(latent_dim=latent_dim, use_attention=True).to(self.device)
            optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)
            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
                optimizer,
                mode='min',
                factor=0.5,
                patience=5
            )

            trainer = WeatherTrainer(
                model=model,
                optimizer=optimizer,
                scheduler=scheduler,
                device=self.device
            )

            model_name = f"sparsity_{int(sparsity*100)}"
            save_path = os.path.join(save_dir, model_name)

            history = trainer.train(
                train_loader=train_loader,
                val_loader=test_loader,
                num_epochs=epochs,
                save_path=save_path,
                save_freq=10
            )

            evaluator = WeatherEvaluator(model, device=self.device)
            metrics = evaluator.evaluate_reconstruction(
                test_loader=test_loader,
                denormalize_fn=test_dataset.denormalize
            )

            self.results['models'][sparsity] = model
            self.results['metrics'][sparsity] = metrics
            self.results['history'][sparsity] = history

            print(f"\n===== Performance Metrics at {sparsity:.1%} Sparsity =====")
            for key, value in metrics.items():
                print(f"{key}: {value:.4f}")

        return self.results

    def visualize_experiment_results(self, save_dir='./results'):
        """
        Create visualizations of experiment results

        Args:
            save_dir: Directory to save visualizations

        Returns:
            list: List of generated figures
        """
        figures = []

        os.makedirs(save_dir, exist_ok=True)

        if not self.results.get('metrics') or not self.results.get('models'):
            print("No experiment results available to visualize.")
            return figures

        for sparsity, history in self.results.get('history', {}).items():
            fig = ModelVisualizer.plot_training_history(history)
            fig.suptitle(f"Training Progress with {sparsity:.1%} Sparsity", fontsize=16)
            fig.savefig(os.path.join(save_dir, f'training_history_sparsity_{int(sparsity*100)}.png'), dpi=300)
            figures.append(fig)

        if self.results.get('metrics'):
            evaluator = WeatherEvaluator()
            comparison_fig = evaluator.compare_sparsity_levels(self.results['metrics'])
            comparison_fig.savefig(os.path.join(save_dir, 'sparsity_comparison.png'), dpi=300)
            figures.append(comparison_fig)

        for sparsity, model in self.results.get('models', {}).items():
            test_dataset = WeatherDataset(
                self.test_files,
                is_training=False,
                sparsity_ratio=sparsity
            )

            evaluator = WeatherEvaluator(model, device=self.device)

            original, corrupted, recon = evaluator.get_reconstructions(
                test_dataset,
                num_samples=5,
                denormalize_fn=test_dataset.denormalize
            )

            recon_fig = evaluator.visualize_reconstructions(
                original, corrupted, recon,
                sparsity=sparsity
            )
            recon_fig.savefig(
                os.path.join(save_dir, f'reconstructions_sparsity_{int(sparsity*100)}.png'),
                dpi=300
            )
            figures.append(recon_fig)

            error_fig = evaluator.visualize_error_map(original, recon)
            error_fig.savefig(
                os.path.join(save_dir, f'error_map_sparsity_{int(sparsity*100)}.png'),
                dpi=300
            )
            figures.append(error_fig)

        return figures

    def create_report_summary(self, save_dir='./results'):
        """
        Create a textual summary of experiment results

        Args:
            save_dir: Directory to save summary

        Returns:
            str: Summary text
        """
        import datetime

        summary = [
            "# Weather DVAE Experiment Results\n",
            f"Date: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
            f"Device: {self.device}\n\n",
            "## Experiment Configuration\n",
            f"- Training Years: {', '.join(str(y) for y in self.years_train)}\n",
            f"- Testing Years: {', '.join(str(y) for y in self.years_test)}\n"
        ]

        if not self.results.get('metrics'):
            summary.append("\n## Status\n")
            summary.append("Experiment did not complete successfully. No metrics available.\n")

            os.makedirs(save_dir, exist_ok=True)
            with open(os.path.join(save_dir, 'experiment_summary.md'), 'w') as f:
                f.write(''.join(summary))

            return ''.join(summary)

        summary.append(f"- Sparsity Levels: {', '.join(f'{s:.1%}' for s in self.results['metrics'].keys())}\n\n")
        summary.append("## Performance Summary\n")

        summary.append("| Sparsity | RMSE | MAE | SSIM | Explained Variance |\n")
        summary.append("| -------- | ---- | --- | ---- | ------------------ |\n")

        for sparsity, metrics in sorted(self.results['metrics'].items()):
            summary.append(
                f"| {sparsity:.1%} | "
                f"{metrics.get('rmse', 'N/A'):.4f} | "
                f"{metrics.get('mae', 'N/A'):.4f} | "
                f"{metrics.get('ssim', 'N/A'):.4f} | "
                f"{metrics.get('explained_variance', 'N/A'):.4f} |\n"
            )

        os.makedirs(save_dir, exist_ok=True)
        with open(os.path.join(save_dir, 'experiment_summary.md'), 'w') as f:
            f.write(''.join(summary))

        return ''.join(summary)

# @title CIRRUS: Usage

def main():
    """
    Main function to run the weather VAE experiment
    """
    data_path = '/content/drive/MyDrive/data_AM160_final/'

    train_files = []
    for year in ['1979', '1980', '1981', '1983']:
        file_path = os.path.join(data_path, f'z{year}.nc')
        if os.path.exists(file_path):
            train_files.append(file_path)
        else:
            print(f"Warning: Training file {file_path} not found")

    test_files = []
    for year in ['1985']:
        file_path = os.path.join(data_path, f'z{year}.nc')
        if os.path.exists(file_path):
            test_files.append(file_path)
        else:
            print(f"Warning: Test file {file_path} not found")

    if not train_files or not test_files:
        print("Error: No data files found. Please ensure the NetCDF files are available.")
        print("Make sure you've mounted your Google Drive with: drive.mount('/content/drive')")
        return

    years_train = [os.path.basename(f).replace('z', '').replace('.nc', '') for f in train_files]
    years_test = [os.path.basename(f).replace('z', '').replace('.nc', '') for f in test_files]

    print(f"Using training files: {train_files}")
    print(f"Using test files: {test_files}")

    sparsity_levels = [0.3, 0.6, 0.9]

    experiment = WeatherExperiment(
        data_path=data_path,
        years_train=years_train,
        years_test=years_test
    )

    try:
        model_path = '/content/drive/MyDrive/am160/final/models'
        results_path = '/content/drive/MyDrive/am160/final/results'
        results = experiment.run_sparsity_experiment(
            sparsity_levels=sparsity_levels,
            epochs=20,
            batch_size=32,
            save_dir=model_path
        )

        experiment.visualize_experiment_results(save_dir=results_path)

        summary = experiment.create_report_summary(save_dir=results_path)
        print("Summary:")
        print(summary)

        print("Experiment complete!")

    except Exception as e:
        print(f"Error during experiment: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()

# @title ___
from google.colab import runtime

# runtime.unassign()
1/0

# @title CIRRUS: Load and Visualize

def load_and_evaluate_models(model_path, data_path, output_path, sparsity_levels=[0.3, 0.6, 0.9]):
    """
    Load pre-trained models and evaluate them on test data

    Args:
        model_path: Path to directory containing saved models
        data_path: Path to data directory
        output_path: Path to save evaluation results
        sparsity_levels: List of sparsity levels to evaluate
    """
    # Create output directory if it doesn't exist
    os.makedirs(output_path, exist_ok=True)

    # Device configuration
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    # Load test data files
    test_files = [os.path.join(data_path, 'z1985.nc')]

    # Check if files exist
    if not os.path.exists(test_files[0]):
        print(f"Error: Test file {test_files[0]} not found")
        return

    # Dictionary to store results
    results = {
        'models': {},
        'metrics': {}
    }

    # For each sparsity level
    for sparsity in sparsity_levels:
        print(f"\n{'='*80}")
        print(f"Loading model for sparsity level: {sparsity:.1%}")

        # Create test dataset with NO augmentation
        test_dataset = WeatherDataset(
            test_files,
            is_training=False,  # Important: No augmentation for test set
            sparsity_ratio=sparsity,
            normalize=True
        )

        # Create test dataloader
        test_loader = DataLoader(
            test_dataset,
            batch_size=16,
            shuffle=False
        )

        # Initialize model with the same architecture as before
        model = WeatherDVAE(latent_dim=128, use_attention=True, use_circular_pad=True).to(device)

        # Look for saved model checkpoint
        model_name = f"sparsity_{int(sparsity*100)}"
        checkpoint_paths = [
            os.path.join(model_path, f"{model_name}_best.pt"),
            os.path.join(model_path, f"{model_name}_final.pt")
        ]

        # Try to load the model
        checkpoint_loaded = False
        for checkpoint_path in checkpoint_paths:
            if os.path.exists(checkpoint_path):
                try:
                    checkpoint = torch.load(checkpoint_path, map_location=device)
                    model.load_state_dict(checkpoint['model_state_dict'])
                    print(f"Successfully loaded model from {checkpoint_path}")
                    checkpoint_loaded = True
                    break
                except Exception as e:
                    print(f"Error loading model from {checkpoint_path}: {e}")

        if not checkpoint_loaded:
            print(f"No model found for sparsity level {sparsity:.1%}, skipping")
            continue

        # Create evaluator
        evaluator = WeatherEvaluator(model, device=device)

        # Evaluate the model
        metrics = evaluator.evaluate_reconstruction(
            test_loader=test_loader,
            denormalize_fn=test_dataset.denormalize
        )

        # Store results
        results['models'][sparsity] = model
        results['metrics'][sparsity] = metrics

        print(f"Performance metrics for sparsity {sparsity:.1%}:")
        for key, value in metrics.items():
            print(f"  {key}: {value:.4f}")

        # Generate visualizations
        original, corrupted, recon = evaluator.get_reconstructions(
            test_dataset,
            num_samples=5,
            denormalize_fn=test_dataset.denormalize  # Ensure we're denormalizing data
        )

        # Check the shape of the arrays to determine how many levels/channels there are
        print(f"Visualization - Original shape: {original.shape}, Corrupted shape: {corrupted.shape}, Recon shape: {recon.shape}")

        # Determine how many levels we have
        num_levels = original.shape[2] if len(original.shape) >= 3 else 1

        # Visualize reconstructions - Avoid using cartopy to prevent GeometryCollection errors
        for level_idx in range(num_levels):
            # Create visualization without using cartopy projection
            try:
                recon_fig = evaluator.visualize_reconstructions(
                    original, corrupted, recon,
                    level_idx=level_idx,
                    channel_idx=0,  # For simplicity, always use first channel
                    sparsity=sparsity,
                    projection='none'  # This signals to use simple imshow instead of cartopy
                )
                recon_fig.savefig(
                    os.path.join(output_path,
                                f'reconstructions_level{level_idx+1}_sparsity_{int(sparsity*100)}.png'),
                    dpi=300, bbox_inches='tight'
                )
                plt.close(recon_fig)
            except Exception as e:
                print(f"Error creating reconstruction visualization for level {level_idx+1}: {e}")
                import traceback
                traceback.print_exc()

    # Create comparison visualization across sparsity levels
    if results['metrics']:
        try:
            comparison_fig = WeatherEvaluator().compare_sparsity_levels(results['metrics'])
            comparison_fig.savefig(
                os.path.join(output_path, 'sparsity_comparison.png'),
                dpi=300, bbox_inches='tight'
            )
            plt.close(comparison_fig)
        except Exception as e:
            print(f"Error creating sparsity comparison: {e}")
            import traceback
            traceback.print_exc()

    return results

# Example usage
if __name__ == "__main__":
    # Set paths
    model_path = '/content/drive/MyDrive/am160/final/models'
    data_path = '/content/drive/MyDrive/data_AM160_final/'
    output_path = '/content/drive/MyDrive/am160/final/evaluation_results'

    # Define sparsity levels to evaluate
    sparsity_levels = [0.3, 0.6, 0.9]

    # Load models and run evaluation
    results = load_and_evaluate_models(
        model_path=model_path,
        data_path=data_path,
        output_path=output_path,
        sparsity_levels=sparsity_levels
    )

    print("Evaluation complete!")

"""# NIMBUS: **N**ext-state **I**nference **M**odel **B**uilt **U**pon CIRR**US**"""

# @title NIMBUS: Data Module

class SequentialWeatherDataset(Dataset):
    """
    Dataset for sequential weather data (for autoregressive prediction)
    """
    def __init__(self, file_paths, is_training=True, normalize=True):
        """
        Initialize dataset

        Args:
            file_paths: List of paths to NetCDF files
            is_training: Whether this is a training dataset
            normalize: Whether to normalize the data
        """
        self.data = []

        # Load data from all files
        for file_path in file_paths:
            ds = nc.Dataset(file_path, 'r')
            z = ds.variables['z'][:]
            self.data.append(z)
            ds.close()

        # Concatenate data from multiple files
        self.data = np.concatenate(self.data, axis=0)

        # Store original data statistics
        self.orig_mean = np.mean(self.data)
        self.orig_std = np.std(self.data)

        # Normalize data if requested
        if normalize:
            self.data = (self.data - self.orig_mean) / self.orig_std

        self.is_training = is_training
        self.normalize = normalize

    def __len__(self):
        # One less than total length since we need pairs (t, t+1)
        return len(self.data) - 1

    def __getitem__(self, idx):
        # Get current state (t)
        x_current = self.data[idx].copy()
        # Get next state (t+1)
        x_next = self.data[idx + 1].copy()

        # Add channel dimension for Conv3D
        x_current = x_current.reshape(1, *x_current.shape)  # Shape: [1, 2, 91, 180]
        x_next = x_next.reshape(1, *x_next.shape)          # Shape: [1, 2, 91, 180]

        return {
            'current': torch.FloatTensor(x_current),
            'next': torch.FloatTensor(x_next),
            'time_idx': idx
        }

    def denormalize(self, data):
        """
        Convert normalized data back to original scale
        """
        if self.normalize:
            if isinstance(data, torch.Tensor):
                return data * self.orig_std + self.orig_mean
            else:
                return data * self.orig_std + self.orig_mean
        return data

# @title NIMBUS: Model Architecture

class WeatherAutoregressiveSimple(nn.Module):
    def __init__(self, base_model, latent_dim=128):
        super().__init__()
        self.base_model = base_model
        self.latent_dim = latent_dim

        # Freeze the base model weights
        for param in self.base_model.parameters():
            param.requires_grad = False

        # Direct prediction in latent space
        self.predictor = nn.Sequential(
            nn.Linear(base_model.latent_dim, base_model.latent_dim * 2),
            nn.ReLU(),
            nn.Linear(base_model.latent_dim * 2, base_model.latent_dim)
        )

    def forward(self, x_current):
        # Get current state encoding
        mask = torch.ones_like(x_current)  # No masking for encoding
        with torch.no_grad():
            current_mu, _ = self.base_model.encode(x_current, mask)

        # Predict next latent state directly
        next_mu = self.predictor(current_mu)

        # Decode to get reconstruction of next state
        x_next_pred = self.base_model.decode(next_mu)

        return x_next_pred, next_mu, current_mu

class WeatherAutoregressiveVAE(nn.Module):
    """
    Autoregressive VAE model that works directly in the latent space
    """
    def __init__(self, base_model, latent_dim=128):
        super().__init__()
        self.base_model = base_model
        self.latent_dim = latent_dim

        # Freeze the base model weights
        for param in self.base_model.parameters():
            param.requires_grad = False

        # Just use a simple MLP for encoding and decoding
        self.encoder = nn.Sequential(
            nn.Linear(self.base_model.latent_dim * 2, self.latent_dim * 2),
            nn.LayerNorm(self.latent_dim * 2),
            nn.LeakyReLU(0.2)
        )

        self.fc_mu = nn.Linear(self.latent_dim * 2, self.latent_dim)
        self.fc_logvar = nn.Linear(self.latent_dim * 2, self.latent_dim)

        self.decoder = nn.Sequential(
            nn.Linear(self.latent_dim + self.base_model.latent_dim, self.base_model.latent_dim),
            nn.LayerNorm(self.base_model.latent_dim),
            nn.LeakyReLU(0.2)
        )

    def encode(self, x_next, x_current):
        """
        Encode to latent space
        Args:
            x_next: Next state [B, 1, 2, H, W]
            x_current: Current state [B, 1, 2, H, W]
        Returns:
            tuple: (mu, logvar) for latent space
        """
        # Use base model to get latent representations
        mask = torch.ones_like(x_next)
        with torch.no_grad():
            next_mu, _ = self.base_model.encode(x_next, mask)
            current_mu, _ = self.base_model.encode(x_current, mask)

        # Concatenate latent vectors
        combined = torch.cat([next_mu, current_mu], dim=1)

        # Process with encoder
        h = self.encoder(combined)

        # Get latent distribution parameters
        mu = self.fc_mu(h)
        logvar = self.fc_logvar(h)

        return mu, logvar, current_mu

    def reparameterize(self, mu, logvar):
        """Sample from latent distribution"""
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std

    def decode(self, z, current_mu):
        """
        Decode latent to reconstruction
        Args:
            z: Latent vector [B, latent_dim]
            current_mu: Current state latent [B, base_latent_dim]
        Returns:
            Reconstructed next state
        """
        # Concatenate with current state latent
        combined = torch.cat([z, current_mu], dim=1)

        # Process with decoder to get latent for base model
        base_latent = self.decoder(combined)

        # Use base model decoder to get reconstruction
        with torch.no_grad():
            x_recon = self.base_model.decode(base_latent)

        return x_recon

    def forward(self, x_next, x_current):
        """Forward pass"""
        mu, logvar, current_mu = self.encode(x_next, x_current)
        z = self.reparameterize(mu, logvar)
        x_next_recon = self.decode(z, current_mu)

        return x_next_recon, mu, logvar, z

    def predict_next(self, x_current):
        """Predict next state"""
        # Get current state latent
        mask = torch.ones_like(x_current)
        with torch.no_grad():
            current_mu, _ = self.base_model.encode(x_current, mask)

        # Sample random latent
        z = torch.randn(x_current.size(0), self.latent_dim, device=x_current.device)

        # Decode to get next state prediction
        x_next_pred = self.decode(z, current_mu)

        return x_next_pred

    def predict_sequence(self, x_start, num_steps):
        """Autoregressively predict a sequence"""
        predictions = []
        x_current = x_start

        for _ in range(num_steps):
            x_next = self.predict_next(x_current)
            predictions.append(x_next)
            x_current = x_next

        return torch.stack(predictions, dim=1)

class WeatherProgressivePredictor(nn.Module):
    def __init__(self, base_model):
        super().__init__()
        self.base_model = base_model

        # Freeze base model
        for param in self.base_model.parameters():
            param.requires_grad = False

        # Extract useful dimensions from base model
        self.latent_dim = base_model.latent_dim

        # Define a temporal dynamics module that operates directly on weather fields
        self.temporal_encoder = nn.Sequential(
            nn.Conv3d(1, 32, kernel_size=(1,3,3), padding=(0,1,1)),
            nn.ReLU(),
            nn.Conv3d(32, 64, kernel_size=(1,3,3), padding=(0,1,1)),
            nn.ReLU(),
            nn.Conv3d(64, 32, kernel_size=(1,3,3), padding=(0,1,1)),
            nn.ReLU()
        )

        # Module to predict change in latent space
        self.latent_predictor = nn.Sequential(
            nn.Linear(self.latent_dim + 32*2*91*180, 1024),
            nn.LayerNorm(1024),
            nn.ReLU(),
            nn.Linear(1024, self.latent_dim),
            nn.Tanh()  # Bounded output for stability
        )

        # Scaling factor for latent changes (learnable)
        self.delta_scale = nn.Parameter(torch.tensor(0.1))

    def forward(self, x_current):
        # Extract features directly from the weather field
        field_features = self.temporal_encoder(x_current)

        # Flatten spatial features
        field_features_flat = field_features.flatten(start_dim=1)

        # Get current latent representation from base model
        mask = torch.ones_like(x_current)
        with torch.no_grad():
            current_mu, _ = self.base_model.encode(x_current, mask)

        # Combine latent and spatial features
        combined = torch.cat([current_mu, field_features_flat], dim=1)

        # Predict change in latent space
        delta_latent = self.latent_predictor(combined)

        # Apply scaled change to get next latent representation
        next_latent = current_mu + self.delta_scale * delta_latent

        # Decode to get predicted next state
        x_next_pred = self.base_model.decode(next_latent)

        return x_next_pred, next_latent, current_mu, delta_latent

    def predict_next(self, x_current):
        """Method for compatibility with evaluation code"""
        x_next_pred, _, _, _ = self.forward(x_current)
        return x_next_pred

    def predict_sequence(self, x_start, num_steps):
        """Autoregressively predict a sequence"""
        predictions = []
        x_current = x_start

        for _ in range(num_steps):
            x_next = self.predict_next(x_current)
            predictions.append(x_next)
            x_current = x_next

        return torch.stack(predictions, dim=1)

# @title NIMBUS: Training Module

def simple_prediction_loss(x_next_pred, x_next_true):
    """
    Simple MSE loss for initial training
    """
    # Basic reconstruction loss
    mse_loss = F.mse_loss(x_next_pred, x_next_true, reduction='mean')
    return mse_loss

def autoregressive_weather_loss(x_next_pred, x_next_true, x_current, mu, logvar, loss_weights=None):
    """
    Enhanced loss function for autoregressive weather prediction, similar to
    the original weather_dvae_loss but adapted for temporal prediction
    Args:
        x_next_pred: Predicted next state [batch, 1, 2, H, W]
        x_next_true: Ground truth next state [batch, 1, 2, H, W]
        x_current: Current state [batch, 1, 2, H, W]
        mu: Mean of latent distribution
        logvar: Log variance of latent distribution
        loss_weights: Optional dictionary with weights for loss components
    Returns:
        tuple: (Total weighted loss, Loss components dictionary)
    """
    # Default loss component weights (similar to original)
    if loss_weights is None:
        loss_weights = {
            'reconstruction': 0.7,    # Much higher focus on basic reconstruction
            'kl': 0.005,              # Lower KL weight
            'gradient': 0.1,          # Reduce gradient weight
            'multiscale': 0.1,        # Reduce multiscale weight
            'temporal': 0.1           # Initially reduce temporal to focus on basics
        }
    # Get batch size for normalization
    batch_size = x_next_true.size(0)
    # 1. Basic reconstruction loss
    recon_loss = F.mse_loss(x_next_pred, x_next_true, reduction='sum')
    # 2. Spatial gradient preservation (as in original)
    # Calculate gradients in latitude and longitude directions
    grad_lat_true = x_next_true[:, :, :, 1:, :] - x_next_true[:, :, :, :-1, :]  # Latitude gradient
    grad_lon_true = x_next_true[:, :, :, :, 1:] - x_next_true[:, :, :, :, :-1]  # Longitude gradient
    grad_lat_pred = x_next_pred[:, :, :, 1:, :] - x_next_pred[:, :, :, :-1, :]
    grad_lon_pred = x_next_pred[:, :, :, :, 1:] - x_next_pred[:, :, :, :, :-1]
    grad_lat_loss = F.mse_loss(grad_lat_pred, grad_lat_true, reduction='sum')
    grad_lon_loss = F.mse_loss(grad_lon_pred, grad_lon_true, reduction='sum')
    spatial_grad_loss = grad_lat_loss + grad_lon_loss
    # 3. Multi-scale analysis (as in original)
    scale = 2  # Downsample factor
    x_next_true_down = F.avg_pool3d(x_next_true, kernel_size=(1, scale, scale))
    x_next_pred_down = F.avg_pool3d(x_next_pred, kernel_size=(1, scale, scale))
    scale_mse = F.mse_loss(x_next_pred_down, x_next_true_down, reduction='sum')
    # 4. Temporal gradient preservation (new component)
    # Ensure the model preserves how the field changes over time
    temporal_grad_true = x_next_true - x_current
    temporal_grad_pred = x_next_pred - x_current
    temporal_grad_loss = F.mse_loss(temporal_grad_pred, temporal_grad_true, reduction='sum')
    # 5. KL divergence (standard from VAE)
    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
    # Final combined loss with weights
    total_loss = (
        loss_weights['reconstruction'] * recon_loss +
        loss_weights['gradient'] * spatial_grad_loss +
        loss_weights['multiscale'] * scale_mse +
        loss_weights['temporal'] * temporal_grad_loss
    ) / batch_size + loss_weights['kl'] * kl_loss / batch_size
    # For tracking individual components (normalized)
    loss_components = {
        'total': total_loss.item(),
        'reconstruction': (recon_loss / batch_size).item(),
        'spatial_gradient': (spatial_grad_loss / batch_size).item(),
        'multiscale': (scale_mse / batch_size).item(),
        'temporal_gradient': (temporal_grad_loss / batch_size).item(),
        'kl': (kl_loss / batch_size).item()
    }
    return total_loss, loss_components

def train_progressive_autoregressive(base_model, train_loader, val_loader, device,
                                     num_epochs=20, lr=0.001, model_save_path=None, save_freq=5):
    # Create model
    model = WeatherProgressivePredictor(base_model).to(device)

    # Use Adam with weight decay to prevent overfitting
    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)

    # History for tracking metrics
    history = {
        'train_loss': [],
        'val_loss': [],
        'loss_components': []
    }

    # Best validation loss
    best_val_loss = float('inf')

    # Training loop with progressive loss components
    for epoch in range(num_epochs):
        model.train()
        train_loss = 0.0
        train_components = {
            'reconstruction': 0.0,
            'delta_reg': 0.0,
            'temporal': 0.0
        }

        # Progressively change loss weights
        progress = epoch / num_epochs
        alpha = min(1.0, progress * 2)  # Increase focus on temporal aspects over time

        for batch in train_loader:
            x_current = batch['current'].to(device)
            x_next = batch['next'].to(device)

            optimizer.zero_grad()

            # Forward pass
            x_next_pred, next_latent, current_mu, delta_latent = model(x_current)

            # Basic reconstruction loss
            recon_loss = F.mse_loss(x_next_pred, x_next)

            # Progressive regularization on latent change
            # Start strict (small changes) then allow more freedom
            delta_reg = torch.mean(delta_latent**2) * (1.0 - alpha)

            # Temporal dynamics loss - becomes more important over time
            temporal_loss = F.mse_loss(x_next_pred - x_current, x_next - x_current) * alpha

            # Combined loss
            loss = recon_loss + delta_reg + temporal_loss

            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()

            # Track losses
            train_loss += loss.item()
            train_components['reconstruction'] += recon_loss.item()
            train_components['delta_reg'] += delta_reg.item()
            train_components['temporal'] += temporal_loss.item()

        # Calculate average losses
        num_batches = len(train_loader)
        train_loss /= num_batches
        train_components = {k: v / num_batches for k, v in train_components.items()}

        # Validation
        model.eval()
        val_loss = 0.0
        val_components = {
            'reconstruction': 0.0,
            'delta_reg': 0.0,
            'temporal': 0.0
        }

        with torch.no_grad():
            for batch in val_loader:
                x_current = batch['current'].to(device)
                x_next = batch['next'].to(device)

                # Forward pass
                x_next_pred, next_latent, current_mu, delta_latent = model(x_current)

                # Calculate losses (same as training)
                recon_loss = F.mse_loss(x_next_pred, x_next)
                delta_reg = torch.mean(delta_latent**2) * (1.0 - alpha)
                temporal_loss = F.mse_loss(x_next_pred - x_current, x_next - x_current) * alpha

                loss = recon_loss + delta_reg + temporal_loss

                # Track losses
                val_loss += loss.item()
                val_components['reconstruction'] += recon_loss.item()
                val_components['delta_reg'] += delta_reg.item()
                val_components['temporal'] += temporal_loss.item()

        # Calculate average validation losses
        num_val_batches = len(val_loader)
        val_loss /= num_val_batches
        val_components = {k: v / num_val_batches for k, v in val_components.items()}

        # Update history
        history['train_loss'].append(train_loss)
        history['val_loss'].append(val_loss)
        history['loss_components'].append(train_components)

        # Save checkpoint if improved
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            if model_save_path is not None:
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'history': history,
                    'val_loss': val_loss
                }, f"{model_save_path}_best.pt")
                print(f"Checkpoint saved to {model_save_path}_best.pt")

        # Save periodic checkpoint
        if model_save_path is not None and (epoch + 1) % save_freq == 0:
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'history': history,
                'val_loss': val_loss
            }, f"{model_save_path}_epoch{epoch+1}.pt")
            print(f"Checkpoint saved to {model_save_path}_epoch{epoch+1}.pt")

        # Print progress
        print(f"Epoch {epoch+1}/{num_epochs} - "
              f"Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}, "
              f"Alpha: {alpha:.2f}")

    # Save final model
    if model_save_path is not None:
        torch.save({
            'epoch': num_epochs,
            'model_state_dict': model.state_dict(),
            'history': history,
            'val_loss': val_loss
        }, f"{model_save_path}_final.pt")
        print(f"Checkpoint saved to {model_save_path}_final.pt")

    return model, history

# @title NIMBUS: Evaluation Module

def evaluate_autoregressive_model(model, test_loader, device, denormalize_fn=None):
    """
    Evaluate the autoregressive model on test data

    Args:
        model: Trained autoregressive model
        test_loader: DataLoader for test data
        device: Device to evaluate on
        denormalize_fn: Function to denormalize data

    Returns:
        dict: Evaluation metrics
    """
    model.eval()

    # Track metrics
    metrics = {
        'rmse': [],
        'rmse_by_channel': [[] for _ in range(2)],  # For 2 channels
        'mae': []
    }

    with torch.no_grad():
        for batch in tqdm(test_loader, desc='Evaluating'):
            # Get batch data
            x_current = batch['current'].to(device)
            x_next_true = batch['next'].to(device)

            # Predict next state
            x_next_pred = model.predict_next(x_current)

            # Always denormalize for consistent evaluation
            if denormalize_fn is not None:
                x_next_true_np = denormalize_fn(x_next_true).cpu().numpy()
                x_next_pred_np = denormalize_fn(x_next_pred).cpu().numpy()
            else:
                x_next_true_np = x_next_true.cpu().numpy()
                x_next_pred_np = x_next_pred.cpu().numpy()

            # Calculate metrics for each sample
            for i in range(x_next_true.size(0)):
                # Overall RMSE
                mse = ((x_next_true_np[i] - x_next_pred_np[i])**2).mean()
                metrics['rmse'].append(np.sqrt(mse))

                # MAE
                mae = np.abs(x_next_true_np[i] - x_next_pred_np[i]).mean()
                metrics['mae'].append(mae)

                # Per-channel RMSE
                for c in range(2):  # For each channel
                    mse_c = ((x_next_true_np[i, 0, c] - x_next_pred_np[i, 0, c])**2).mean()
                    metrics['rmse_by_channel'][c].append(np.sqrt(mse_c))

    # Aggregate metrics
    agg_metrics = {
        'rmse': np.mean(metrics['rmse']),
        'mae': np.mean(metrics['mae']),
        'rmse_channel_1': np.mean(metrics['rmse_by_channel'][0]),
        'rmse_channel_2': np.mean(metrics['rmse_by_channel'][1])
    }

    return agg_metrics


def predict_and_evaluate_sequence(model, initial_state, ground_truth_sequence, num_steps, device,
                                 denormalize_fn=None):
    """
    Predict a sequence and evaluate against ground truth

    Args:
        model: Trained autoregressive model
        initial_state: Initial state [1, 1, 2, H, W]
        ground_truth_sequence: Ground truth sequence [num_steps, 1, 2, H, W]
        num_steps: Number of steps to predict
        device: Device to evaluate on
        denormalize_fn: Function to denormalize data

    Returns:
        tuple: (predictions, metrics)
    """
    model.eval()

    # Move initial state to device
    x_start = initial_state.to(device)

    # Predict sequence
    with torch.no_grad():
        predictions = model.predict_sequence(x_start, num_steps)

    # Denormalize if needed - ensure we're always denormalizing
    if denormalize_fn is not None:
        predictions_np = denormalize_fn(predictions).cpu().numpy()
        ground_truth_np = denormalize_fn(ground_truth_sequence).cpu().numpy()
    else:
        predictions_np = predictions.cpu().numpy()
        ground_truth_np = ground_truth_sequence.cpu().numpy()

    # Calculate metrics
    metrics = {
        'rmse_over_time': [],
        'mae_over_time': [],
        'rmse_by_channel_over_time': [[] for _ in range(2)]  # For 2 channels
    }

    for t in range(num_steps):
        # Overall RMSE for this time step
        mse_t = ((predictions_np[:, t] - ground_truth_np[t:t+1])**2).mean()
        metrics['rmse_over_time'].append(np.sqrt(mse_t))

        # MAE for this time step
        mae_t = np.abs(predictions_np[:, t] - ground_truth_np[t:t+1]).mean()
        metrics['mae_over_time'].append(mae_t)

        # Per-channel RMSE
        for c in range(2):  # For each channel
            mse_tc = ((predictions_np[:, t, 0, c] - ground_truth_np[t:t+1, 0, c])**2).mean()
            metrics['rmse_by_channel_over_time'][c].append(np.sqrt(mse_tc))

    # Convert predictions to numpy if needed
    if isinstance(predictions, torch.Tensor):
        predictions_np = predictions.cpu().numpy()
    else:
        predictions_np = predictions

    # Convert ground truth to numpy if needed
    if isinstance(ground_truth_sequence, torch.Tensor):
        ground_truth_np = ground_truth_sequence.cpu().numpy()
    else:
        ground_truth_np = ground_truth_sequence

    return predictions_np, metrics

# @title NIMBUS: Visualization Module

def visualize_sequence_prediction(predictions, ground_truth, time_indices=None, level_idx=0,
                               channel_idx=0, grid_coords=None, projection=None,
                               cmap='jet'):  # Default to 'jet'
    """
    Visualize sequence predictions compared to ground truth without using cartopy
    to avoid GeometryCollection errors

    Args:
        predictions: Predicted sequence data with shape [time, channel, lat, lon]
        ground_truth: Ground truth sequence data with shape [time, channel, lat, lon]
        time_indices: Specific time steps to visualize
        level_idx: Index of pressure level to visualize
        channel_idx: Index of channel to visualize
        grid_coords: Optional dictionary with lats and lons
        projection: Map projection to use (if None or 'none', uses simple imshow)
        cmap: Colormap to use (default: 'jet')
    """
    # Print input shapes for debugging
    print(f"Input predictions shape: {predictions.shape}")
    print(f"Input ground_truth shape: {ground_truth.shape}")

    # Get number of time steps
    num_steps = min(predictions.shape[0], ground_truth.shape[0])

    if time_indices is None:
        time_indices = [0, 1, 2, 4, 9] if num_steps > 9 else list(range(num_steps))

    time_indices = [t for t in time_indices if t < num_steps]
    num_times = len(time_indices)

    # Determine if we should use cartopy or not
    use_cartopy = projection is not None and projection != 'none'

    # Create figure with or without cartopy
    if use_cartopy:
        try:
            fig, axes = plt.subplots(num_times, 2, figsize=(15, 5*num_times),
                                   subplot_kw={'projection': projection})
        except Exception as e:
            print(f"Error creating figure with cartopy: {e}")
            # Fallback to standard plotting
            use_cartopy = False
            fig, axes = plt.subplots(num_times, 2, figsize=(15, 5*num_times))
    else:
        fig, axes = plt.subplots(num_times, 2, figsize=(15, 5*num_times))

    # Handle single row case
    if num_times == 1:
        axes = axes.reshape(1, -1)

    fig.suptitle(f"Autoregressive Prediction Results (Pressure Level {level_idx+1}, Channel {channel_idx+1})",
                fontsize=16, y=0.98)

    # Set up coordinates if needed for cartopy
    lat_size = ground_truth.shape[2] if len(ground_truth.shape) >= 3 else ground_truth.shape[1]
    lon_size = ground_truth.shape[3] if len(ground_truth.shape) >= 4 else ground_truth.shape[2]

    if grid_coords is None:
        lats = np.linspace(-90, 90, lat_size)
        lons = np.linspace(0, 360, lon_size, endpoint=False)
    else:
        lats = grid_coords['lats']
        lons = grid_coords['lons']

    lon_mesh, lat_mesh = np.meshgrid(lons, lats)

    # Extract data for all time steps first for consistent color scaling
    all_data = []
    for t in time_indices:
        # Extract data for this time step from both true and predicted
        if len(ground_truth.shape) >= 4:  # Shape like [time, channel, level, lat, lon] or [time, level, lat, lon]
            if level_idx < ground_truth.shape[1]:
                true_t = ground_truth[t, level_idx]
            else:
                true_t = ground_truth[t]
        else:
            true_t = ground_truth[t]

        if len(predictions.shape) >= 4:
            if level_idx < predictions.shape[1]:
                pred_t = predictions[t, level_idx]
            else:
                pred_t = predictions[t]
        else:
            pred_t = predictions[t]

        all_data.append(true_t.flatten())
        all_data.append(pred_t.flatten())

    # Calculate global min/max for consistent color scaling
    all_data = np.concatenate(all_data)
    vmin = np.percentile(all_data, 1)
    vmax = np.percentile(all_data, 99)
    contour_levels = np.linspace(vmin, vmax, 20)

    # For each time step
    for i, t in enumerate(time_indices):
        # Extract data for this time step
        if len(ground_truth.shape) >= 4:  # Shape like [time, channel, level, lat, lon] or [time, level, lat, lon]
            if level_idx < ground_truth.shape[1]:
                true_t = ground_truth[t, level_idx]
            else:
                true_t = ground_truth[t]
        else:
            true_t = ground_truth[t]

        if len(predictions.shape) >= 4:
            if level_idx < predictions.shape[1]:
                pred_t = predictions[t, level_idx]
            else:
                pred_t = predictions[t]
        else:
            pred_t = predictions[t]

        # Plot ground truth
        ax = axes[i, 0]
        if use_cartopy:
            try:
                contour = ax.contourf(lon_mesh, lat_mesh, true_t,
                                     transform=ccrs.PlateCarree(),
                                     cmap=cmap, levels=contour_levels, extend='both')
                try:
                    ax.coastlines(resolution='110m', color='black', linewidth=0.5)
                except:
                    pass  # Skip coastlines if they cause problems
                ax.gridlines(draw_labels=True, linewidth=0.5, color='gray', alpha=0.5, linestyle='--')
            except Exception as e:
                print(f"Error with cartopy plot: {e}")
                # Fall back to imshow
                contour = ax.imshow(true_t, cmap=cmap, vmin=vmin, vmax=vmax, aspect='auto')
                ax.grid(False)
        else:
            # Use simple imshow
            contour = ax.imshow(true_t, cmap=cmap, vmin=vmin, vmax=vmax, aspect='auto')
            ax.grid(True, linestyle='--', alpha=0.3)

        # Update title to include 6-hour time steps
        ax.set_title(f'Ground Truth (t+{(t+1)*6}h)')
        plt.colorbar(contour, ax=ax, orientation='horizontal', pad=0.05, shrink=0.8)

        # Plot prediction
        ax = axes[i, 1]
        if use_cartopy:
            try:
                contour = ax.contourf(lon_mesh, lat_mesh, pred_t,
                                     transform=ccrs.PlateCarree(),
                                     cmap=cmap, levels=contour_levels, extend='both')
                try:
                    ax.coastlines(resolution='110m', color='black', linewidth=0.5)
                except:
                    pass  # Skip coastlines if they cause problems
                ax.gridlines(draw_labels=True, linewidth=0.5, color='gray', alpha=0.5, linestyle='--')
            except Exception as e:
                print(f"Error with cartopy plot: {e}")
                # Fall back to imshow
                contour = ax.imshow(pred_t, cmap=cmap, vmin=vmin, vmax=vmax, aspect='auto')
                ax.grid(False)
        else:
            # Use simple imshow
            contour = ax.imshow(pred_t, cmap=cmap, vmin=vmin, vmax=vmax, aspect='auto')
            ax.grid(True, linestyle='--', alpha=0.3)

        # Update title to include 6-hour time steps
        ax.set_title(f'Prediction (t+{(t+1)*6}h)')
        plt.colorbar(contour, ax=ax, orientation='horizontal', pad=0.05, shrink=0.8)

        # Add axis labels if not using cartopy
        if not use_cartopy:
            ax.set_xlabel('Longitude')
            ax.set_ylabel('Latitude')

    plt.tight_layout()
    return fig

def visualize_both_levels(predictions, ground_truth, output_path, time_indices=None, prefix="sequence_predictions"):
    """
    Create separate visualizations for each pressure level and channel, matching CIRRUS style

    Args:
        predictions: Predicted sequence data with shape [time, channel, lat, lon]
        ground_truth: Ground truth sequence data with shape [time, channel, lat, lon]
        output_path: Path to save the visualization figures
        time_indices: Specific time steps to visualize
        prefix: Prefix for the output filenames
    """
    # Number of pressure levels
    n_levels = predictions.shape[1]

    # Create a visualization for each level and channel
    for level_idx in range(n_levels):
        for channel_idx in range(predictions.shape[2] if len(predictions.shape) > 3 else 1):
            # Create figure with CIRRUS-style settings
            fig = visualize_sequence_prediction(
                predictions=predictions,
                ground_truth=ground_truth,
                time_indices=time_indices,
                level_idx=level_idx,  # Each plot shows only one level
                channel_idx=channel_idx,  # Each plot shows only one channel
                cmap='jet'  # Using jet colormap as requested
            )

            # Save the figure
            fig_path = os.path.join(output_path, f"{prefix}_level{level_idx+1}_channel{channel_idx+1}.png")
            fig.savefig(fig_path, dpi=300, bbox_inches='tight')
            plt.close(fig)

            print(f"Saved visualization for level {level_idx+1}, channel {channel_idx+1} to {fig_path}")

    print(f"Visualization complete - created {n_levels} level-specific plots for each channel")

def prepare_data_for_visualization(predictions, ground_truth):
    """
    Prepare prediction and ground truth data for visualization

    Args:
        predictions: Model predictions - could be various formats
        ground_truth: Ground truth sequence data

    Returns:
        tuple: (prepared_predictions, prepared_ground_truth)
    """
    # Print original shapes for debugging
    print(f"Original predictions shape: {predictions.shape}")
    print(f"Original ground_truth shape: {ground_truth.shape}")

    # Handle predictions based on shape
    # If predictions has shape [batch, time, channel, channel, lat, lon]
    if len(predictions.shape) == 6:
        # Take the first batch item
        prepared_predictions = predictions[0]
    # If predictions has shape [time, 1, 2, lat, lon]
    elif len(predictions.shape) == 5:
        # Reshape to [time, channel, lat, lon]
        prepared_predictions = predictions[:, 0]
    else:
        prepared_predictions = predictions

    # Handle ground truth based on shape
    # If ground_truth has shape [time, 1, 2, lat, lon]
    if len(ground_truth.shape) == 5:
        prepared_ground_truth = ground_truth[:, 0]
    else:
        prepared_ground_truth = ground_truth

    # Print final shapes for verification
    print(f"Prepared predictions shape: {prepared_predictions.shape}")
    print(f"Prepared ground_truth shape: {prepared_ground_truth.shape}")

    return prepared_predictions, prepared_ground_truth

def plot_prediction_error_over_time(metrics, channel_names=["Channel 1", "Channel 2"]):
    """
    Plot prediction error metrics over time

    Args:
        metrics: Dictionary with metrics over time
        channel_names: List of channel names

    Returns:
        matplotlib.figure.Figure: Figure with error plots
    """
    fig, axes = plt.subplots(1, 2, figsize=(16, 6))

    # Get time steps - convert to hours (each step is 6 hours)
    time_steps = np.arange(1, len(metrics['rmse_over_time']) + 1) * 6

    # X-axis labels for hours
    x_ticks = time_steps
    x_labels = [f"{t}h" for t in time_steps]

    # Plot overall RMSE
    axes[0].plot(time_steps, metrics['rmse_over_time'], 'o-', linewidth=2, markersize=8,
                label='Overall RMSE', color='#1f77b4')

    # Add grid
    axes[0].grid(True, linestyle='--', alpha=0.7)

    # Set x-ticks with hour labels
    axes[0].set_xticks(x_ticks)
    axes[0].set_xticklabels(x_labels)

    # Add labels and title
    axes[0].set_xlabel('Forecast Time (Hours)', fontsize=12)
    axes[0].set_ylabel('RMSE', fontsize=12)
    axes[0].set_title('Overall Prediction Error Over Time', fontsize=14)

    # Plot per-channel RMSE
    for i, channel_name in enumerate(channel_names):
        color = ['#ff7f0e', '#2ca02c'][i % 2]  # Alternate colors
        if i < len(metrics['rmse_by_channel_over_time']):
            # Square the RMSE to get MSE
            channel_mse = [rmse**2 for rmse in metrics['rmse_by_channel_over_time'][i]]
            axes[1].plot(time_steps, channel_mse, 'o-', linewidth=2, markersize=8,
                       label=channel_name, color=color)

    # Add grid
    axes[1].grid(True, linestyle='--', alpha=0.7)

    # Set x-ticks with hour labels
    axes[1].set_xticks(x_ticks)
    axes[1].set_xticklabels(x_labels)

    # Add labels and title
    axes[1].set_xlabel('Forecast Time (Hours)', fontsize=12)
    axes[1].set_ylabel('MSE', fontsize=12)
    axes[1].set_title('MSE Between Predicted and True Values by Channel', fontsize=14)
    axes[1].legend(fontsize=10)

    plt.tight_layout()
    return fig

# @title NIMBUS: Implementation

def run_autoregressive_prediction(base_model_path, data_path, output_path=None, save_model_path=None, sparsity=0.3):
    """
    Main function to implement autoregressive prediction

    Args:
        base_model_path: Path to the base model directory
        data_path: Path to the data directory
        output_path: Path to save evaluation results (plots, metrics)
        save_model_path: Path to save model checkpoints
        sparsity: Sparsity level of the base model to use
    """
    # Set default paths if not provided
    if output_path is None:
        output_path = '/content/drive/MyDrive/am160/final/autoregressive_results'

    if save_model_path is None:
        save_model_path = '/content/drive/MyDrive/am160/final/models'

    # Create output directory
    os.makedirs(output_path, exist_ok=True)
    os.makedirs(save_model_path, exist_ok=True)

    # Device configuration
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    # Load base model
    base_model = WeatherDVAE(latent_dim=128, use_attention=True, use_circular_pad=True)

    # Load pretrained weights
    checkpoint_path = os.path.join(base_model_path, f"sparsity_{int(sparsity*100)}_best.pt")
    if not os.path.exists(checkpoint_path):
        # Try alternatives
        alt_paths = [
            os.path.join(base_model_path, f"sparsity_{int(sparsity*100)}_final.pt"),
            os.path.join(base_model_path, f"sparsity_{int(sparsity*100)}.pt")
        ]
        for path in alt_paths:
            if os.path.exists(path):
                checkpoint_path = path
                break

    # Load model
    checkpoint = torch.load(checkpoint_path, map_location=device)
    base_model.load_state_dict(checkpoint['model_state_dict'])
    base_model.to(device)
    base_model.eval()
    print(f"Loaded base model from {checkpoint_path}")

    # Prepare datasets
    train_files = [os.path.join(data_path, f'z{year}.nc') for year in ['1979', '1980', '1981', '1983']]
    val_files = [os.path.join(data_path, 'z1983.nc')]  # Use the last part of 1983 for validation
    test_files = [os.path.join(data_path, 'z1985.nc')]  # Use 1985 for testing

    print(f"Using training files: {train_files}")
    print(f"Using test files: {test_files}")

    # Create datasets
    train_dataset = SequentialWeatherDataset(train_files, is_training=True)
    val_dataset = SequentialWeatherDataset(val_files, is_training=False)
    test_dataset = SequentialWeatherDataset(test_files, is_training=False)

    # Create data loaders
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

    # Modify this part - replace the existing model training with:
    print(f"{'='*80}")
    print(f"Starting progressive autoregressive training with base model sparsity: {sparsity*100:.1f}%")
    print(f"{'='*80}")

    # Checkpoints path using the same naming convention as original code
    model_save_path = os.path.join(save_model_path, f"progressive_autoregressive_{int(sparsity*100)}")

    # Train the progressive autoregressive model
    model, history = train_progressive_autoregressive(
        base_model=base_model,
        train_loader=train_loader,
        val_loader=val_loader,
        device=device,
        num_epochs=20,
        lr=0.001,  # Using higher learning rate
        model_save_path=model_save_path,
        save_freq=5
    )

    # Plot training history
    plt.figure(figsize=(12, 6))
    plt.subplot(1, 2, 1)
    plt.plot(history['train_loss'], label='Train Loss')
    plt.plot(history['val_loss'], label='Val Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Total Loss')
    plt.legend()
    plt.grid(True, linestyle='--', alpha=0.7)

    plt.subplot(1, 2, 2)
    components = {'reconstruction': [], 'spatial_gradient': [], 'multiscale': [],
                 'temporal_gradient': [], 'kl': []}

    for epoch_components in history['loss_components']:
        for key, value in epoch_components.items():
            if key in components:
                components[key].append(value)

    for key, values in components.items():
        if values:  # Only plot if we have values
            plt.plot(values, label=key.replace('_', ' ').title())

    plt.xlabel('Epoch')
    plt.ylabel('Loss Component')
    plt.title('Loss Components')
    plt.legend()
    plt.grid(True, linestyle='--', alpha=0.7)

    plt.tight_layout()
    plt.savefig(os.path.join(output_path, "training_history.png"), dpi=300, bbox_inches='tight')
    plt.close()

    # Evaluate on test set
    metrics = evaluate_autoregressive_model(
        model=model,
        test_loader=test_loader,
        device=device,
        denormalize_fn=test_dataset.denormalize
    )

    # Print metrics in similar format to original
    print(f"\n===== Performance Metrics for Autoregressive Model =====")
    for key, value in metrics.items():
        print(f"{key}: {value:.4f}")

    # Save metrics
    with open(os.path.join(output_path, "test_metrics.txt"), 'w') as f:
        f.write("Autoregressive Model Test Metrics:\n")
        for key, value in metrics.items():
            f.write(f"  {key}: {value:.4f}\n")

    # Predict sequence starting from first time step (Jan 1, 1985)
    initial_state = test_dataset[0]['current'].unsqueeze(0)  # Add batch dimension

    # Get ground truth sequence for next 10 days
    num_steps = 10
    ground_truth_sequence = torch.stack([test_dataset[i]['next'] for i in range(num_steps)])

    # Predict and evaluate sequence
    predictions, sequence_metrics = predict_and_evaluate_sequence(
        model=model,
        initial_state=initial_state,
        ground_truth_sequence=ground_truth_sequence,
        num_steps=num_steps,
        device=device,
        denormalize_fn=test_dataset.denormalize
    )

    # Visualize sequence predictions
    # Channel 0
    fig = visualize_sequence_prediction(
        predictions=predictions,
        ground_truth=ground_truth_sequence.numpy(),
        time_indices=[0, 1, 2, 4, 9],  # Day 1, 2, 3, 5, 10
        channel_idx=0
    )
    fig.savefig(os.path.join(output_path, "sequence_predictions_channel1.png"),
               dpi=300, bbox_inches='tight')
    plt.close(fig)

    # Channel 1
    fig = visualize_sequence_prediction(
        predictions=predictions,
        ground_truth=ground_truth_sequence.numpy(),
        time_indices=[0, 1, 2, 4, 9],  # Day 1, 2, 3, 5, 10
        channel_idx=1
    )
    fig.savefig(os.path.join(output_path, "sequence_predictions_channel2.png"),
               dpi=300, bbox_inches='tight')
    plt.close(fig)

    # Plot prediction error over time
    fig = plot_prediction_error_over_time(sequence_metrics)
    fig.savefig(os.path.join(output_path, "prediction_error_over_time.png"),
               dpi=300, bbox_inches='tight')
    plt.close(fig)

    print(f"Results saved to {output_path}")
    return model, metrics, sequence_metrics

# @title NIMBUS: Usage

def main():
    """
    Main function to run the autoregressive weather experiment
    """
    # Set paths
    base_model_path = '/content/drive/MyDrive/am160/final/models'
    data_path = '/content/drive/MyDrive/data_AM160_final/'
    output_path = '/content/drive/MyDrive/am160/final/autoregressive_results'
    save_model_path = '/content/drive/MyDrive/am160/final/models'

    # Run autoregressive prediction using the 30% sparsity model
    model, metrics, sequence_metrics = run_autoregressive_prediction(
        base_model_path=base_model_path,
        data_path=data_path,
        output_path=output_path,
        save_model_path=save_model_path,
        sparsity=0.3
    )

    print("Autoregressive experiment complete!")

if __name__ == "__main__":
    main()

# @title ___
from google.colab import runtime

runtime.unassign()
1/0

# @title NIMBUS: Load and Visualize

def load_and_evaluate_autoregressive_models(model_path, data_path, output_path, sparsity_levels=[0.3]):
    """
    Load pre-trained autoregressive models and evaluate them on test data
    """
    # Create output directory if it doesn't exist
    os.makedirs(output_path, exist_ok=True)

    # Device configuration
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    # Load test data files
    test_files = [os.path.join(data_path, 'z1985.nc')]

    # Check if files exist
    if not os.path.exists(test_files[0]):
        print(f"Error: Test file {test_files[0]} not found")
        return

    # Dictionary to store results
    results = {
        'models': {},
        'metrics': {},
        'sequence_metrics': {}
    }

    # For each sparsity level
    for sparsity in sparsity_levels:
        print(f"\n{'='*80}")
        print(f"Loading autoregressive model for sparsity level: {sparsity:.1%}")

        # Create test dataset
        test_dataset = SequentialWeatherDataset(
            test_files,
            is_training=False,
            normalize=True
        )

        # Create test dataloader
        test_loader = DataLoader(
            test_dataset,
            batch_size=16,
            shuffle=False
        )

        # First load the base model (needed for the autoregressive model)
        base_model = WeatherDVAE(latent_dim=128, use_attention=True, use_circular_pad=True).to(device)

        # Try to load the base model with fallbacks
        base_loaded = False
        base_suffixes = ["_best.pt", "_final.pt", "_epoch50.pt", "_epoch40.pt", "_epoch30.pt"]
        for suffix in base_suffixes:
            checkpoint_path = os.path.join(model_path, f"sparsity_{int(sparsity*100)}{suffix}")
            if os.path.exists(checkpoint_path):
                try:
                    checkpoint = torch.load(checkpoint_path, map_location=device)
                    base_model.load_state_dict(checkpoint['model_state_dict'])
                    print(f"Successfully loaded base model from {checkpoint_path}")
                    base_loaded = True
                    break
                except Exception as e:
                    print(f"Error loading base model from {checkpoint_path}: {e}")

        if not base_loaded:
            print(f"No base model found for sparsity level {sparsity:.1%}, skipping")
            continue

        # Initialize autoregressive model (WeatherProgressivePredictor)
        model = WeatherProgressivePredictor(base_model).to(device)

        # Try to load the autoregressive model
        ar_loaded = False

        # First try the exact path you specified
        target_path = os.path.join(model_path, f"progressive_autoregressive_{int(sparsity*100)}_best.pt")

        # If that fails, use these alternative paths
        alternative_paths = [
            os.path.join(model_path, f"progressive_autoregressive_{int(sparsity*100)}_final.pt"),
            os.path.join(model_path, f"progressive_autoregressive_{int(sparsity*100)}_epoch20.pt"),
            os.path.join(model_path, f"progressive_autoregressive_{int(sparsity*100)}_epoch15.pt"),
            os.path.join(model_path, f"progressive_autoregressive_{int(sparsity*100)}_epoch10.pt"),
            os.path.join(model_path, f"progressive_autoregressive_{int(sparsity*100)}_epoch5.pt"),
            os.path.join(model_path, f"autoregressive_{int(sparsity*100)}_final.pt"),
            os.path.join(model_path, f"autoregressive_{int(sparsity*100)}_best.pt")
        ]

        # Try the target path first
        if os.path.exists(target_path):
            try:
                checkpoint = torch.load(target_path, map_location=device)
                model.load_state_dict(checkpoint['model_state_dict'])
                print(f"Successfully loaded autoregressive model from {target_path}")
                ar_loaded = True
            except Exception as e:
                print(f"Error loading autoregressive model from {target_path}: {e}")
                print("Will try alternative checkpoints...")

        # If that failed, try alternatives
        if not ar_loaded:
            for path in alternative_paths:
                if os.path.exists(path):
                    try:
                        checkpoint = torch.load(path, map_location=device)
                        model.load_state_dict(checkpoint['model_state_dict'])
                        print(f"Successfully loaded autoregressive model from {path}")
                        ar_loaded = True
                        break
                    except Exception as e:
                        print(f"Error loading autoregressive model from {path}: {e}")

        # If still not loaded, give up
        if not ar_loaded:
            print(f"All attempts to load autoregressive model for sparsity {sparsity:.1%} failed.")
            continue

        # Set model to evaluation mode
        model.eval()

        # Evaluate the model on test data
        metrics = evaluate_autoregressive_model(
            model=model,
            test_loader=test_loader,
            device=device,
            denormalize_fn=test_dataset.denormalize  # Make sure to denormalize
        )

        # Store results
        results['models'][sparsity] = model
        results['metrics'][sparsity] = metrics

        print(f"Performance metrics for autoregressive model at sparsity {sparsity:.1%}:")
        for key, value in metrics.items():
            print(f"  {key}: {value:.4f}")

        # Get ground truth sequence for sequence prediction evaluation
        initial_state = test_dataset[0]['current'].unsqueeze(0)  # Add batch dimension
        num_steps = 10
        ground_truth_sequence = torch.stack([test_dataset[i]['next'] for i in range(num_steps)])

        # Predict and evaluate sequence
        predictions, sequence_metrics = predict_and_evaluate_sequence(
            model=model,
            initial_state=initial_state,
            ground_truth_sequence=ground_truth_sequence,
            num_steps=num_steps,
            device=device,
            denormalize_fn=test_dataset.denormalize  # Make sure to denormalize
        )

        # Store sequence metrics
        results['sequence_metrics'][sparsity] = sequence_metrics

        # Now we'll visualize the predictions for each level and channel separately
        for level_idx in range(2):  # We have 2 pressure levels
            for channel_idx in range(2):  # We have 2 channels
                # Extract just this level and channel's data
                try:
                    # Handle predictions - could be various shapes
                    if len(predictions.shape) == 6:  # Shape [1, 10, 1, 2, 91, 180]
                        pred_level_channel = predictions[0, :, 0, level_idx, :, :]  # Shape [10, 91, 180]
                    elif len(predictions.shape) == 5:  # Shape [10, 1, 2, 91, 180]
                        pred_level_channel = predictions[:, 0, level_idx, :, :]  # Shape [10, 91, 180]
                    else:
                        pred_level_channel = predictions[:, level_idx, :, :]  # Shape [10, 91, 180]

                    # Handle ground truth - also could be various shapes
                    if len(ground_truth_sequence.shape) == 5:  # Shape [10, 1, 2, 91, 180]
                        gt_level_channel = ground_truth_sequence.numpy()[:, 0, level_idx, :, :]  # Shape [10, 91, 180]
                    else:
                        gt_level_channel = ground_truth_sequence.numpy()[:, level_idx, :, :]  # Shape [10, 91, 180]

                    # Select time steps to visualize (each step is 6 hours)
                    time_indices = [0, 1, 2, 4, 9]  # 6h, 12h, 18h, 30h, 60h
                    time_indices = [t for t in time_indices if t < len(pred_level_channel)]

                    # Create visualization without using cartopy projection to avoid errors
                    fig = visualize_sequence_prediction(
                        predictions=pred_level_channel,
                        ground_truth=gt_level_channel,
                        time_indices=time_indices,
                        level_idx=level_idx,
                        channel_idx=channel_idx,
                        projection=None,  # Use None to avoid cartopy issues
                        cmap='jet'
                    )

                    # Save figure
                    fig_path = os.path.join(output_path, f"sequence_predictions_level{level_idx+1}_channel{channel_idx+1}_sparsity_{int(sparsity*100)}.png")
                    fig.savefig(fig_path, dpi=300, bbox_inches='tight')
                    plt.close(fig)
                    print(f"Saved visualization for level {level_idx+1}, channel {channel_idx+1} to {fig_path}")

                except Exception as e:
                    print(f"Error creating visualization for level {level_idx+1}, channel {channel_idx+1}: {e}")
                    import traceback
                    traceback.print_exc()

        # Plot prediction error over time
        try:
            fig = plot_prediction_error_over_time(sequence_metrics)
            fig.savefig(os.path.join(output_path, f"prediction_error_over_time_sparsity_{int(sparsity*100)}.png"),
                      dpi=300, bbox_inches='tight')
            plt.close(fig)
        except Exception as e:
            print(f"Error creating error plot: {e}")
            import traceback
            traceback.print_exc()

    return results

if __name__ == "__main__":
    # Set paths
    model_path = '/content/drive/MyDrive/am160/final/models/'
    data_path = '/content/drive/MyDrive/data_AM160_final/'
    output_path = '/content/drive/MyDrive/am160/final/autoregressive_evaluation_results/'

    # Define sparsity levels to evaluate (models must exist for these levels)
    sparsity_levels = [0.3]  # Add more if you have trained models for other sparsity levels

    # Load models and run evaluation
    results = load_and_evaluate_autoregressive_models(
        model_path=model_path,
        data_path=data_path,
        output_path=output_path,
        sparsity_levels=sparsity_levels
    )

    print("Autoregressive model evaluation complete!")